<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>logistic regression on Andriy Koval</title>
    <link>/tags/logistic-regression/</link>
    <description>Recent content in logistic regression on Andriy Koval</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Andriy Koval</copyright>
    <lastBuildDate>Tue, 07 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/logistic-regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Managing Data Analysis with RStudio</title>
      <link>/post/2020-01-07-graphing-models-with-titanic-data/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-01-07-graphing-models-with-titanic-data/</guid>
      <description>Recent example of 1) interpreting models through graphs rather than parameters 2) using self-contains RMarkdown notebook vs .R + .Rmd split</description>
    </item>
    
    <item>
      <title>Managing Data Analysis with RStudio</title>
      <link>/talk/2019-11-26-hsif-toronto-workshop/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/talk/2019-11-26-hsif-toronto-workshop/</guid>
      <description>The workshop introduces R and RStudio and makes the case for project-oriented workflows for applied data analysis. Using logistic regression on Titanic data as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results</description>
    </item>
    
    <item>
      <title>Implementing Reproducible Visualizations</title>
      <link>/talk/2019-11-08-visualizing-logistic-regression/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/talk/2019-11-08-visualizing-logistic-regression/</guid>
      <description>Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs often is the best means to explain and promote research findings. However,in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?</description>
    </item>
    
    <item>
      <title>Visualizing Logistic Regression</title>
      <link>/talk/2018-11-01-visualizing-logistic-regression/</link>
      <pubDate>Thu, 01 Nov 2018 16:00:00 -0700</pubDate>
      
      <guid>/talk/2018-11-01-visualizing-logistic-regression/</guid>
      <description>Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?</description>
    </item>
    
    <item>
      <title>When notebooks are not enough</title>
      <link>/talk/2018-10-31-when-notebooks-are-not-enough/</link>
      <pubDate>Wed, 31 Oct 2018 15:00:00 -0700</pubDate>
      
      <guid>/talk/2018-10-31-when-notebooks-are-not-enough/</guid>
      <description>AbstractWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?
I will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software.</description>
    </item>
    
  </channel>
</rss>