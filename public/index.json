[{"authors":["admin"],"categories":null,"content":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV\n","date":1559088000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1559088000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV","tags":null,"title":"Andriy Koval","type":"authors"},{"authors":[],"categories":["graph making"],"content":"\r\r\rTL;DR\rI gave a workshop on visualizing COVID-19 data in multiple countries, demonstrating how to 1) build interactive visualizations using plotly::ggplotly(), 2) compute relative timelines for each country and 3) plot sequence of key events for cross-country comparison. To structure the workshop and create the criteria of success/progress, I have broken down the session into three parts, each aimed at producing a graphic.\n\r\r\r\rGoal 1\rGoal 2\rGoal 3\r\r\r\rTimeseries with interactive highlights\rTrajectories with relative timelines\rSequence of key epidemiological events\r\r\r\r\r\r\r\rKEY LINKS\n- https://github.com/andkov/vada-2020-summer-school - github repo created to accompany this workshop. Includes data and scripts.\n- Visualizing the Pandemic - dynamic report narrating the workshop. (covers what did not fit into the video)\n\n\rLearning Objectives\rRecently I was invited to give a workshop at the 2020 Summer School event of the Visual and Automated Disease Analytic (VADA) graduate training program, which was held virtually this year due to COVID-19 pandemic.\nNaturally, COVID-19 was featured prominently in the talks and took the center stage during the analytic session on Thursday, the last day of the summer school. My workshop was scheduled to open the workshop series, so I wanted to give the students some tools for visual exploration of longitudinal data. The target learning objectives aspired for participants to be able to:\nPlot time series of COVID-19 cases using ggplot2 package\rAdd interactive highlights to trajectories using plotly package\rCompute indicators for key epidemiological events in each country (e.g. day of the first death)\rConstruct country-specific timelines relative to key epidemiological events\rVisualize the sequence of key events for a group of countries\r\rNow you see why I used “aspired” instead of “intended”. No, I didn’t get to finish it all in under 60 minutes. However, I have anticipated this and created a narrated version fo the workshop which captured all demonstrations I wanted to go through. This dynamic report is best understood in the larger context of the https://github.com/andkov/vada-2020-summer-school repository, which I have created to offer a jump start for comparing COVID-19 trajectories across multiple geographies.\n\r","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592843430,"objectID":"1afd6be38e93e3a97dfecf6fb9e02f08","permalink":"/post/2020-06-22-visualizing-the-pandemic/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/post/2020-06-22-visualizing-the-pandemic/","section":"post","summary":"Demonstrating how to 1) build interactive visualizationsusing `plotly::ggplotly()`, 2) compute relative timelines for each country and 3) plot sequence of key events for cross-country comparison.","tags":["ggplot2","longitudinal analysis","public health","COVID-19"],"title":"Visualizing the Pandemic","type":"post"},{"authors":["Andriy Koval"],"categories":["learning resource"],"content":" Books  R for Data Science by Garrett Grolemund and Hadley Wickham\n Data Visualization with R by Rob Kabacoff\n R Graphics Cookbook by Winston Chang Interactive web-based data visualization with R, plotly, and shiny by Carson Sievert\n Statistical Inference via Data Science.A ModernDive into R and the tidyverse by Chester Ismay and Albert Y. Kim R Programming for Data Science by Roger Peng Hands-On Machine Learning with R Bradley Boehmke \u0026amp; Brandon Greenwell\n An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\n  Courses  Introductory Data Science using R by Derek L. Sonderegger\n Data Visualization by Andrew Heiss\n Discovering Statistics by Andy Field\n Data Visualization in R by Michael Friendly\n  ","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590019200,"objectID":"e1f178c8ff897dcb78ce3686fdf37fc7","permalink":"/post/2020-05-21-online-course-and-textbooks/","publishdate":"2020-05-21T00:00:00Z","relpermalink":"/post/2020-05-21-online-course-and-textbooks/","section":"post","summary":"A list of learning resources that I find particularly useful","tags":["R","ggplot2"],"title":"Online Courses and Textbooks","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","analytic workflow","graph making"],"content":"\r\r\rData\rQ1 - What is the overall trajectory of suicides in FL between 2006 and 2017?\rQ2 - How does change in suicide rates differ by AGE group?\rQ3 - How do suicide trends differ by SEX?\rQ4 - How do suicide trends differ by SEX and AGE group?\rQ5 - How do suicide trends differ by RACE?\rQ6 - How do suicide trends differ by RACE and SEX?\r\r\rThis blogpost graphs the trends of suicides in Florida from 2006 to 2017, exploring the differences in age, sex, and race among persons 10 years and older.\nClick HERE to view report in its native environment of the suicide-prevention-2019 repository.\nData\rThe initial extract of the data was obtained from www.flhealthcharts.com, a reporting tool for population counts estimated by the Florida Department of Health. The dataset contains suicide mortality counts and population estimates for years 2006-2017, broken down by suicide means, county, sex, age group, and race. The .csv of this dataset is available for download. For details regarding data preparation, please consult the suicide-prevention-2019 repository.\n\rQ1 - What is the overall trajectory of suicides in FL between 2006 and 2017?\rSimilar to national trends, the rates of suicide in Florida has been on the rise since 2006. In 2006, the Department of Health registered 2,402 suicides, while in 2017 this number reached 3,141. On average, each year the total number of suicides in Florida increased by 57 during this time. While the rising number of suicides events could be partially explained by demographic growth (see full report for details ), when adjusted for population size the rate per 100,000 still indicated that suicides became more prevalent: the rate increased from 15 in 2006 to 17.2 per 100,000 in 2017, averaging .15 in annual growth.\r\rQ2 - How does change in suicide rates differ by AGE group?\rOnly two age groups, 35-44 and 45-54 exhibited decline in suicide rates, witnessed by a negative slope coefficient in the liniear model, regressing the rate on year. However, examination of the raw data point behind the linear model suggests that negative slope might be coincidental to an overal steady treajectory.\nFor all other age groups, the rates of suicides increased. The highest increase in suicide rates per 100,000 is observed in the 85+ group, for which the rate rose by .64 annualy from 21.3 suicides per 100,000 in 2006 to 25.3 in 2017.\n\rQ3 - How do suicide trends differ by SEX?\rAs expected, suicides are more more prevalent among men. Notably, the increase for men was steeper: from 2006 to 2017 the rate of suicides for men rose from 23.8 to 27.4 per 100,000, averaging .19 per year, wheras for women this increase was smaller, rising from 6.7 to 7.5, over the same time period, averaging .11 per year.\n\rQ4 - How do suicide trends differ by SEX and AGE group?\rThe top view helps comparing the overal level of suicide rates among age groups, accounting for sex differences. We see that the highest rates are among the oldest Floridians: 75-84 and 85+ groups, the latter exhibiting the fastest growth rate of 1.44 per year, rising by almost 20% from 49.2 per 100,000 in 2006 to 58.5 in 2017.\nTo better view the trends withing the age groups, we replot this figure with free y-axis, exposing more nuanced longitudinal trends.\n\rQ5 - How do suicide trends differ by RACE?\rWhite Non-Hispanics exhibit the highest suicide rate and also the steepest growth of .32 suicides per 100,000 per year. The top row of the graph places the trends on the same scale, while the bottom row displays them on individual scale. Note, however, that annual fluctuations are less meaningful for less populous ethnic groups, such as Black \u0026amp; Other + Hispanic\n\rQ6 - How do suicide trends differ by RACE and SEX?\rRegardless of the ethnic group, suicide is more prevalent among men, particularly of the White + Non-Hispanic origin. Notably, white non-hispanic women are more likely to commit suicide than women of any other ethnic group.\rReplotting with free y-axis helps us see that growth in suicide rate among men is not universal across ethnic groups. Suicide rate is actually decreasing among non-white men with Hispanic origin.\r\r","date":1587859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590278400,"objectID":"c0ce31a2103a48b522d48528a54aebf7","permalink":"/post/2020-04-26-florida-suicide-1/","publishdate":"2020-04-26T00:00:00Z","relpermalink":"/post/2020-04-26-florida-suicide-1/","section":"post","summary":"Graphing the trends of suicides in Florida from 2006 to 2017, exploring the differences in age, gender, and race among persons 10 years and older","tags":["suicide","Florida"],"title":"Florida Suicides (1) - General Trends","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","analytic workflow","graph making"],"content":"\r\rAbstract\rThis blogposts shows how to extract population estimates data reported by the Florida Department of Health and prepare them for analysis, specifically, for exploring the trends in demographic growth between 2006 and 2020.\nClick HERE to view report in its native environment of the suicide-prevention-2019 repository.\n\rData Origin\rThe initial extract of the data was obtained from www.flhealthcharts.com, a reporting tool for population counts estimated by the Florida Department of Health. The figure below shows the modifications to the default query the produces the data product used in this demonstration:\nFig 1. View of the reporting tool\n\rThe tool gives the option to save the product of the query as an Excel book (.xls), however, the import of this extension into R has been problematic, so I have converted (“save as”) the file manually into a more modern Excel format, .xlsx. This file is the raw source for the current report and can be dowloaded for closer inspection here.\n\rData import\rThe structure of the Excel file requires some tidying to enable a nimble analytic flow\nFig 2. View of the extracted data\n\r\rData Tweaking\rWe can identify several problems to address:\nNot all columns have names\n\rrace, ethnicity, sex, and age_group are stored in merged spreadsheet cells\n\rSums for categories are recorded in rows as observations (e.g Total)\n\rSome values of age_group are misinterpreted as dates (e.g. 1-4 becomes 4-Jan)\n\rage_group does not bin the population evenly (e.g. 20-24 vs 25-34)\r\rThe cleaned version of this dataset is available for download here.\n\rGraphing\rWe will consider several questions in order to demonstrate plotting from this cleaned dataset.\nHow does the total population of Florida changes between 2006 and 2020?\n\rHow does each ethnic group change during this time?\n\rwhat Ethnic group is most dissimilar from the other three in their dynamics?\n\rWhat would it look like if we used the original age_group?\r\rGraph 1.Total Population\n\rGraph 2. Ethnic groups: Together\n\rGraph 3. Ethnic groups: Separate\n\rGraph 4. Age Composition: 5-year groups\n\rGraph 4. Age Composition: original groups\n\r\r","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585267200,"objectID":"773405c78b6c2e444929ed6de567e072","permalink":"/post/2020-03-27-florida-demographic-growth/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/post/2020-03-27-florida-demographic-growth/","section":"post","summary":"This blogposts shows how to extract population estimates data reported by the Florida Department of Health and prepare them for analysis, specifically, for exploring the trends in demograph growth between 2006 and 2020","tags":["demography","Florida"],"title":"Florida Demographic Growth","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","analytic workflow","graph making"],"content":"\r\rRecently I was invited to give a workshop on data analysis with R at the training retreat for Health System Impact Fellowship by Canadian Institutes of Health Research.\n#CIHR_ImpactFellows immersed in a hands-on RStudio workshop, led by @andkovpro, Assistant Prof @ UCF and alumnus of the 2017 fellow cohort. Thank you @andkovpro ! #HSIF2019 #enrichedcorecomps #datascience pic.twitter.com/P0Qp3saMQF\n\u0026mdash; Meghan McMahon (@McMahon_Meg) November 26, 2019  The workshop was hosted at the picturesque Hart House of the University of Toronto:\nThe workshop involved\nAudience\rMy audience constisted of postdoctoral researchers and Ph.D. students, few of whom had experience with R, however majority have taken 3 or more courses in statistics and applied analysis. To gain better understanding of their background, I have asked them to fill out a brief survey (see results in my slides)\nI had about 90 minutes, so I reasoned that instead of overwhelming them with technical information, which would leave little trace in their fatigued minds ( workshop was at the end of the day), I should create a resource that they would be able to use in the future. The time in workshop, then, should spent on gentle introduction to data analysis with R using the examples from this resource. This also gave my workshop the flexibility to accomodate learners of various skill levels: more advanced participants will have the material to study on their own if the talk leaves them underchallenged in any given point in time.\n\rLearning Objectives\rI wanted the audience to be exposed to examples of performing the following tasks:\nOrganizing data analysis in a RMarkdown document\n\rGraphing the predictions of a statistical model (logistic regression)\n\rJump-starting an analytic project using a project template\r\r\rDeliverables\r1. Organizing data analysis in a RMarkdown document\rI have created two reports, containing identidcal code that implemented basic exploration of Titanic data with logistic regression:\r- notebook-only - a notebook combining code and annotation in the same .Rmd file\r- separate-layers - a report separating the analytic layer (.R) from the annotation layer (.Rmd)\n\rpresentation slides\r\r\rGraphing a model\rCarefull not to overwhelm with details, I chose to focus on a basic logistic regression model predicting survival in the Titanic data.\n# Model 0\rsurvived ~ sex\r# Model 1\rsurvived ~ sex + age\r# Model 2\rsurvived ~ sex + age + passenger_class\r# Model 3\rsurvived ~ sex + age + passenger_class + port_embarked\r\rHowever, instead of focusing on interpreting the estimated parameters, I opted to generate predicted values and then to graph them to examine the effect respective variables would have on the binary outcome. We converted the log-odds into probabilities of the outcome (y-axis) and then mapped predictors on other visual dimension. To illustrate, the prediction for Model 2 survived ~ sex + age + passenger_class looked like this:\nmodel_2\n\r\rMaterials\r\rnotebook-only - analytic report as a notebook (combines code and annotation in the same .Rmd file)\rseparate-layers - analytic report separating the analytic layer (.R) from the annotation layer (.Rmd)\rpresentation slides\r\r\rAbstract\rThe workshop will review best practices of reproducible research including folder architecture, data preparation, graph making, statistical modeling, and script documentation. The workshop is targeted at researchers who are expected to conduct their own analysis of data and prepare reports that deliver the findings to both technical and executive audiences within health systems. Using logistic regression as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results.\n\r\r","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579996800,"objectID":"761f5d74c6a782b0825829cbd4f5a4b9","permalink":"/post/2020-01-07-graphing-models-with-titanic-data/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/post/2020-01-07-graphing-models-with-titanic-data/","section":"post","summary":"Recent example of 1) interpreting models through graphs rather than parameters 2) using self-contains RMarkdown notebook vs .R + .Rmd split  ","tags":["logistic regression","ggplot2"],"title":"Managing Data Analysis with RStudio","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","workflow","tidyverse"],"content":"\rMaterials\r\rnotebook-only - analytic report as a notebook (combines code and annotation in the same .Rmd file)\rseparate-layers - analytic report separating the analytic layer (.R) from the annotation layer (.Rmd)\rpresentation slides\r\r\rAbstract\rThe workshop will review best practices of reproducible research including folder architecture, data preparation, graph making, statistical modeling, and script documentation. The workshop is targeted at researchers who are expected to conduct their own analysis of data and prepare reports that deliver the findings to both technical and executive audiences within health systems. Using logistic regression as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results.\n\r","date":1574726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574899200,"objectID":"65bb67c0c9ba86af60e8a74819bda0d2","permalink":"/talk/2019-11-26-hsif-toronto-workshop/","publishdate":"2019-11-26T00:00:00Z","relpermalink":"/talk/2019-11-26-hsif-toronto-workshop/","section":"talk","summary":"The workshop introduces R and RStudio and makes the case for project-oriented workflows for applied data analysis. Using logistic regression on Titanic data as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results","tags":["logistic regression","ggplot2"],"title":"Managing Data Analysis with RStudio","type":"talk"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rVisualising results of statistical modeling is a key component of data science workflow. Statistical graphs often is the best means to explain and promote research findings. However,in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives? This talk will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon.\nThe system evaluates synthetic socioeconomic and mortality data with logistic regression. The data was prepared for the hackathon by Statistic Canada and represents Canadian population. First, I will introduce a visualisation technique that uses color to create a meaningful expectations from the results of a logistic regression. Then I will discuss the workflow of the project that implements this graphing system ( github.com/andkov/ipdln-2018-hackathon ). I will conclude by building the case to prefer reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\n","date":1572998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573084800,"objectID":"870a87a076b3aa5ab823c99fd4e733a1","permalink":"/talk/2019-11-08-visualizing-logistic-regression/","publishdate":"2019-11-06T00:00:00Z","relpermalink":"/talk/2019-11-08-visualizing-logistic-regression/","section":"talk","summary":"Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs often is the best means to explain and promote research findings. However,in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?","tags":["logistic regression","ggplot2","coloring book","graphing techniques","hackathon"],"title":"Implementing Reproducible Visualizations","type":"talk"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics","Mental Health \u0026 Substance Use","Reproducible Research"],"content":"\rThis report demonstrate what disappears from the view of service utilization analysts when only Emergency and Acute Care data are mined from the EHR, a common practice in health services research. We study the cohort of 4,067 residents of Vancouver Island with severe alcohol addiction. Engagement with the cross-continuum terrain of services is aggraged over 10 years (2007 - 2017) and reported via categories of the Clinical Context Coding Scheme of the Vancouver Island Health Authority.\nRead the full report\nPlay with the pivot of results\nFigure 1: Aggregate cohort engagement of service classes: acute (red) and community (grey)\n\r","date":1564704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564704000,"objectID":"5a9eed4157a906826d635e4a6b1e3403","permalink":"/post/2019-08-01-what-lies-beyond-acute-care/","publishdate":"2019-08-02T00:00:00Z","relpermalink":"/post/2019-08-01-what-lies-beyond-acute-care/","section":"post","summary":"Using service utilization data of 4,067 residents of Vancouver Island with sever alcohol addiction we demonstrate the cross-continuum terrain of health services in Vancouver Island Health Authority.","tags":["electronic health records","heavy addiction","alcohol","substance abuse","health service utilization"],"title":"What Lies Beyond Acute Care Data","type":"post"},{"authors":[],"categories":[],"content":"\rI am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr. Andrea Piccinin and Dr. Scott Hofer. With IALSA, I worked on developing reproducible analytics (R + GitHub) for remote collaboration, particularly for implementing coordinated statistical analyses among multiple longitudinal studies of aging via remote participation.\nInterest in data-driven narratives of human aging lead me to explore the use of electronic health records (EHR) for research and improvement of patient care. Since October 2015 I have been working with Dr. Kenneth Moselle, the director of the Applied Clinical Research Unit (ACRU) of Vancouver Island Health Authority (VIHA) on curating the transformation of VIHA’s EHR into analyzable form and creating opportunities for academic and clinical researchers to work with these data in responsible and reproducible way. Together with Dr. Moselle I have launched a Data Science Studio at the University of Victoria, a research unit at the Institute on Aging and Lifelong Health dedicated to supporting its research affiliates and UVic students in accessing, handling, and modeling cross-continuum health records of VIHA.\nAt ACRU I worked on bridging healthcare data to analytic capacities of longitudinal modelling. My functions at ACRU included statistical and programming support for research and quality improvement projects, coordinating communication and empowering collaboration among three audiences: database managers, medical practitioners, and academic researchers. The overlap in my skills in statistical modeling, programming, and knowledge of VIHA’s electronic health records gave me a unique advantage to facilitate such a collaboration, the integrative nature of which offered great promises for improving patient care, medical science, and methodological practices of longitudinal research.\nIn August of 2017 I was awarded a CIHR Health System Impact Fellowship with BC Observatory for Population and Public Health of the BC Centre for Disease Control ($140,000 + $15,000 development fund). My program of work involved developing a system for population health surveillance that would focus on chronic diseases, with particular focus on mental health and substance use (MHSU) conditions, which tend to have high comorbidity rates, polysubstance use patterns, and slowly progressing pace of development. Drawing on my experience with EHR system employed by VIHA, I engaged various statistical modeling and learning techniques to construct analytic workflows capable of supporting clinical decisions at the point of service, while translating the acquired knowledge to be consumed by clinical stewards, system planners, and surveillance agencies.\nmindset\rData scientists describe the ultimate reality about data using various dialets of expression. Each translation has its benefits and disadvantages. We need them all to tell a good story.\nNo one language is better than the other. Each allows for different shades of distinction in model specification.\n\r","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561058495,"objectID":"b29fbe32d2b65a7f442839fc78fb3f21","permalink":"/post/academic-biography/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/academic-biography/","section":"post","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr.","tags":[],"title":"Academic Biography","type":"post"},{"authors":["Andriy Koval","Anthony Leamon","Kate Smolina"],"categories":["suppress-for-release"],"content":"\r\rPoster presented at the 2019 conference of the Canadian Association for Health Services and Policy Research, Halifax, Nova Scotia.\nNote: The number in parentheses (1) refers to the section of the poster.\nTake away points\r\rReproducible pipelines are hard, but they pay off\rThink of cognitive load first, computational load second\rInvest into dependency maps for (re-)learning forms \u0026amp; functions\rInvest into workflow maps for (re-)learning structures \u0026amp; processes\r\r\rBackground\rIn 2016, the Observatory for Population \u0026amp; Public Health of British Columbia launched the Chronic Disease Dashboard, an online reporting tool designed to address the gap in surveillance of chronic diseases. To protect against re-identification risks, the Ministry of Health required redacting small counts prior to releasing disease rates into public domain. These preparations, when conducted manually, have proven to be arduous, time consuming, and prone to human error.\n\rApproach\rWhile finding a “small” count (operationalized as “ \u0026lt; 5 ”) was straightforward, detecting conditions, in which suppressed values could be recalculated from related cells involved human judgement. As part of the embedded research by their Health System Impact Fellow (2017), the Observatory set out to automate this task, designing a reproducible workflow ( see section 5 of the poster ) that split data into disease-by-year data frames of a specific form ( 1 ), applied a sequence of logical tests ( 2 ) written to recognize conditions that made recalculation of suppressed values possible and printed a graph ( 6 ) for each case of suggested automatic redaction to be confirmed by a human ( 7 ).\n\rResults\rThe automated suppression was successfully integrated into the Dashboard maintenance. Data preparation, application of logical tests, and production of visual evidence were implemented in R and published as a version-controlled RStudio project on Github github.com/ihacru/suppress-for-release. A fully reproducible example with fictional data was made available to demonstrate the current logic of suppression and to ensure the availability of documentation for the future staff of the Observatory charged with Dashboard maintenance. To assist with learning, we designed a map of dependencies among the custom functions used for suppression ( 4 ) and illustrated their use in a simplified workflow ( 3 ), which allows studying the performance of logical tests before engaging the real data to applying the suppression logic ( 5 ) and to document the redaction decisions ( 7 ) Anticipating the evolution of suppression logic, we moduralized the logical tests ( 2 ) responsible for redaction and provided several options to vary the degree of preserved information ( blue vs light blue ).\n\rConclusions\rThis case of embedded research demonstrates the benefits and feasibility of integrating practices of reproducible analytics into routine workflow of epidemiological surveillance. We make a strong case for employing such learning devices as workflow maps ( 5 ) and function dependency trees ( 4 ) for structuring applied projects and ensuring their reproducibility.\n\r","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"1b96832744a02fc81fab3ac2a5a8410b","permalink":"/publication/koval-2018-severity-burden-mental-health/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/publication/koval-2018-severity-burden-mental-health/","section":"publication","summary":"Demonstrates the methods of suppressing small counts in a provincial surveillance system in preparation of data for public release.","tags":["small cell suppression","chronic disease surveillance","public health","reproducible research","ggplot2"],"title":"Suppressing Small Counts for Public Release","type":"publication"},{"authors":["Andriy Koval","Anthony Leamon","Kate Smolina"],"categories":["suppress-for-release"],"content":"\rPoster presented at the 2019 conference of the Canadian Association for Health Services and Policy Research, Halifax, Nova Scotia.\nNote: The number in parentheses (1) refers to the section of the poster.\nTake away points\r\rReproducible pipelines are hard, but they pay off\rThink of cognitive load first, computational load second\rInvest into dependency maps for (re-)learning forms \u0026amp; functions\rInvest into workflow maps for (re-)learning structures \u0026amp; processes\r\r\rBackground\rIn 2016, the Observatory for Population \u0026amp; Public Health of British Columbia launched the Chronic Disease Dashboard, an online reporting tool designed to address the gap in surveillance of chronic diseases. To protect against re-identification risks, the Ministry of Health required redacting small counts prior to releasing disease rates into public domain. These preparations, when conducted manually, have proven to be arduous, time consuming, and prone to human error.\n\rApproach\rWhile finding a “small” count (operationalized as “ \u0026lt; 5 ”) was straightforward, detecting conditions, in which suppressed values could be recalculated from related cells involved human judgement. As part of the embedded research by their Health System Impact Fellow (2017), the Observatory set out to automate this task, designing a reproducible workflow ( see section 5 of the poster ) that split data into disease-by-year data frames of a specific form ( 1 ), applied a sequence of logical tests ( 2 ) written to recognize conditions that made recalculation of suppressed values possible and printed a graph ( 6 ) for each case of suggested automatic redaction to be confirmed by a human ( 7 ).\n\rResults\rThe automated suppression was successfully integrated into the Dashboard maintenance. Data preparation, application of logical tests, and production of visual evidence were implemented in R and published as a version-controlled RStudio project on Github github.com/ihacru/suppress-for-release. A fully reproducible example with fictional data was made available to demonstrate the current logic of suppression and to ensure the availability of documentation for the future staff of the Observatory charged with Dashboard maintenance. To assist with learning, we designed a map of dependencies among the custom functions used for suppression ( 4 ) and illustrated their use in a simplified workflow ( 3 ), which allows studying the performance of logical tests before engaging the real data to applying the suppression logic ( 5 ) and to document the redaction decisions ( 7 ) Anticipating the evolution of suppression logic, we moduralized the logical tests ( 2 ) responsible for redaction and provided several options to vary the degree of preserved information ( blue vs light blue ).\n\rConclusions\rThis case of embedded research demonstrates the benefits and feasibility of integrating practices of reproducible analytics into routine workflow of epidemiological surveillance. We make a strong case for employing such learning devices as workflow maps ( 5 ) and function dependency trees ( 4 ) for structuring applied projects and ensuring their reproducibility.\n\r","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"68cee25142656a0448bc697f37c52ad4","permalink":"/publication/koval-2019-suppress-for-release/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/publication/koval-2019-suppress-for-release/","section":"publication","summary":"Demonstrates the methods of suppressing small counts in a provincial surveillance system in preparation of data for public release.","tags":["small cell suppression","chronic disease surveillance","public health","reproducible research","ggplot2"],"title":"Suppressing Small Counts for Public Release","type":"publication"},{"authors":["Emily C Duggan","Andrea M Piccinin","Sean Clouston","Andriy Koval","Annie Robitalle","Andrea R Zammit","Chenkai Wu","Cassandra L Brown","Lewina O Lee","Deborah Finkel","William H. Beasley","Jeffrey Kaye","Graciela Muniz Terrera","Mindy Katz","Richard B Lipton","Dorly Deeg","David A Bennett","Marcus Praetorius Björk","Boo Johansson","Avron Spiro II","Jennifer Weuve","Scott M Hofer"],"categories":["coordinated analysis","IALSA-Portland"],"content":"\rBackground\rSubstantial research is dedicated to understanding the aging-related dynamics among individual differences in level, change, and variation across physical and cognitive abilities. Evaluating replicability and synthesizing these findings has been limited by differences in measurements and samples, and by study design and statistical analyses confounding between-person differences with within-person changes. In this article, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.\n\rMethods\rWe performed coordinated analysis of bivariate growth models in data from 20,586 participants across eight longitudinal studies to examine individual differences in baseline level, rate of change, and occasion-specific variability in pulmonary and cognitive functioning. Results were summarized using meta-analysis.\n\rResults\rWe found consistent but weak baseline and longitudinal associations in levels of pulmonary and cognitive functioning, but no associations in occasion-specific variability.\n\rConclusions\rResults provide limited evidence for a consistent link between simultaneous changes in pulmonary and cognitive function in a normal aging population. Further research is required to understand patterns of onset of decline and differences in rates of change within and across physical and cognitive functioning domains, both within-individuals and across countries and birth cohorts. Coordinated analysis provides an efficient and rigorous approach for replicating and comparing results across independent longitudinal studies.\nSee more\n\r","date":1551484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551484800,"objectID":"50d7843ace7e770a5eb69bfc5db9ddb4","permalink":"/publication/duggan-2018-pulmonary-cognition-aging/","publishdate":"2019-03-02T00:00:00Z","relpermalink":"/publication/duggan-2018-pulmonary-cognition-aging/","section":"publication","summary":"In this second paper of a two-paper series, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.","tags":["pulmonary","cognition","cognitive aging","normative aging","longitudinal analysis"],"title":"A Multi-Study Coordinated Meta-Analysis of Pulmonary Function and Cognition in Aging","type":"publication"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rVisualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?\nThis presentation will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon. The system evaluates synthetic socioeconomic and mortality data with logistic regression. The data was prepared for the hackathon by Statistic Canada and represents Canadian population.\nTopics covered will include:\n\rIntroduction to a visualisation technique that uses color to create meaningful expectations from the results of a logistic regression.\rDetails related to the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon )\rBuilding the case for preference of reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\r\rVideo\r\r\r","date":1541113200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"010a0c32feb7228a67d237e138834c59","permalink":"/talk/2018-11-01-visualizing-logistic-regression/","publishdate":"2018-11-01T16:00:00-07:00","relpermalink":"/talk/2018-11-01-visualizing-logistic-regression/","section":"talk","summary":"Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?","tags":["logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"Visualizing Logistic Regression","type":"talk"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rAbstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software. First, I will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon, organized by Statistics Canada. The system evaluates synthetic socioeconomic and mortality data with logistic regression. Then I will discuss the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon ) and the RStudio + GitHub setup that hosts it. I will conclude by building the case to prefer reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\n\rTable of Content\rFigure 1\n\r\rLayers of Isolation\rFigure 2\n\r\r","date":1541023200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"9ad4009290131c1caf1cde78229fbc07","permalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","publishdate":"2018-10-31T15:00:00-07:00","relpermalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","section":"talk","summary":"Abstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software.","tags":["literate programming","computational essays","logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"When notebooks are not enough","type":"talk"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics"],"content":"\rPoster presented at the 2018 conference of the International Population Data Linkage Association, Banff, Alberta.\n","date":1537660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537660800,"objectID":"ade67b61c6a9760a8540d24f99cd88fb","permalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","publishdate":"2018-09-23T00:00:00Z","relpermalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","section":"publication","summary":"Demonstrates how cross-continuum terrain of health services can be described in with flexible classification scheme.","tags":["cccs"],"title":"Clinical Context Coding Scheme","type":"publication"},{"authors":["Andriy Koval","Kate Smolina","Scott M. Hofer","Ken Moselle"],"categories":["Health Informatics","Health Services Research","MHSU"],"content":"\r\rPoster presented at the 30th conference of the Centre for Health Services and Policy Research, Vancouver, BC\n\nIn this poster we present a framework for planning and implementing research projects that rely on skills and techniques of “data science” to generate actionable knowledge from linked, full-cross-continuum health data in the context of learning healthcare system.\nFirst, we lay out the elements of the general framework for applied health data science (AHDS), exemplifying a generic workflow process. Then we delineate critical features of the environments for data access and data analysis that are critical to ensuring practical reproducibility - a paramount consideration for building a healthcare system that learns.\nUsing an ongoing research program at the Stroke Rapid Assessment Unit at VIHA, we proceed to demonstrate how a specific implementation of this framework transmutes into the research/analytical core of the Cognitive Health Initiative (CHI), which pursues a combination of computerized cognitive assessments and provider-generated clinical records to advance the accuracy of diagnosing and to improve patient care. Data visualizations of person-level and cohort-level are provided.\nWe conclude by demonstrating how this framework could be instantiated to support two projects of the current HSI fellow. The first project, explores the predictive capacity of clinical transactions (i.e. how healthcare system was engaged by the patient) to anticipate catastrophic medical events, such as opioid overdose (OO) or a death from an OO. The second project aims to leverage directly off of transactional records generated at a full continuum of services to enhance the surveillance of MHSU conditions, which are notoriously prone to be misrepresented by administrative sources of data.\n","date":1520467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520467200,"objectID":"cbf582c53037ce7e5064d846b9e8097c","permalink":"/publication/koval-2018-blueprints-for-learning/","publishdate":"2018-03-08T00:00:00Z","relpermalink":"/publication/koval-2018-blueprints-for-learning/","section":"publication","summary":"Describes the tools and framework for identifying, describing, and analyzing person- and cohort- level service utilization in complex health service terrain.","tags":["clinical context code scheme","health services","mental health","substance use","chronic disease surveillance","public health"],"title":"Blueprints for Learning","type":"publication"},{"authors":["Amanda Kelly","Matthew Calamia","Andriy Koval","Graciela Muniz-Terrera","Andrea M.Piccinin","Sean Clouston","Linda B.Hassing","David A. Bennett","Boo Johansson","Scott M.Hofer"],"categories":["coordinated analysis"],"content":"\r","date":1456358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456358400,"objectID":"3445af2e990ad454352aed5822303af0","permalink":"/publication/kelly-2016-hypertension-diabetes-memory/","publishdate":"2016-02-25T00:00:00Z","relpermalink":"/publication/kelly-2016-hypertension-diabetes-memory/","section":"publication","summary":"The study explored the effects of living with Hypertension and Diabetes Mellitus on declarative memory performace using data from longitudinal studies from England, Sweden, and the United States.","tags":["cognition","cognitive aging","diabetes","hypertension","longitudinal analysis"],"title":"Independent and Interactive Impacts of Hypertension and Diabetes Mellitus on Verbal Memory","type":"publication"},{"authors":["Andriy Koval"],"categories":["reproducible research"],"content":"\rThe lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.\nOf specific importance is the data grooming stage, which enables a productive exploration of the data and establishes custody chains to support research conclusions based on the analytic products.\n","date":1412899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412899200,"objectID":"d2d2d10b1433ca923ab615ade69d4d28","permalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","publishdate":"2014-10-10T00:00:00Z","relpermalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","section":"talk","summary":"The lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.","tags":["data science","analytic workflow","dynamic documentation","computational essays"],"title":"Toolbox and Toolsets of Reproducible Research","type":"talk"},{"authors":["Andriy Koval"],"categories":["thesis"],"content":"\r\rdownload pdf\nDefended on December 5, 2004, in fulfillment of requirements by the Honors College of Middle Tennessee State University. Thesis explores the history of brand advertising and its implementation in the emergent market economy of post-soviet Ukraine, investigating the effects of western marketing campaigns on the fabric of interpersonal relations and communication using face-to-face survey.\nTable of Content\rPart I. Advertising and Branding : History, Concepts, Psychology\rChapter 1. Introduction and major concepts\nChapter 2. Origins of consumer culture 1865-1917\nChapter 3. Evolution in the market place\nChapter 4. De-personalization of markets and growth of individualism\nChapter 5. Advertising/Branding - Psychological concepts and applications\nChapter 6. Model of brand advertising\n- Function 1. Informational and pseudo-information\n- Function 2. Self-identification\n- Function 3. Self-expression\n\rPart II. The Brandless Country\rChapter 7. Advertising in the Soviet Union\nChapter 8. Advertising in Independent Ukraine\n- A. Who owns advertising industry in Ukraine?\n- B. Who owns business in Ukraine?\n- C. Who spends the most on advertising?\n- D. Who has most popular brands?\n\rPart III. Research and analysis\rChapter 9. Purpose, Design, Makeup, Hypotheses\nChapter 10. Results and Analysis\nChapter 11. Conclusion\n\rBibliography\r\rAppendix\r\r\r","date":1102204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1102204800,"objectID":"7883f2ea3fcbc625aeeeed8a072314e5","permalink":"/publication/koval-2004-undergraduate-thesis/","publishdate":"2004-12-05T00:00:00Z","relpermalink":"/publication/koval-2004-undergraduate-thesis/","section":"publication","summary":"Explores the history of brand advertising and its implementation in the emergence market economy of post-soviet Ukraine, specifically the effects of western marketing campaigns on the fabric of interpersonal relations and communication.","tags":["advertising","survey","Ukraine"],"title":"Influence of Brand Advertising on the Nature of Interpersonal Communication in Ukrainian Society","type":"publication"}]