[{"authors":["admin"],"categories":null,"content":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV\n","date":1559088000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1559088000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV","tags":null,"title":"Andriy Koval","type":"authors"},{"authors":["Andriy Koval"],"categories":["reproducible research","analytic workflow","graph making"],"content":"\r\rAbstract\rThis blogposts shows how to extract population estimates data reported by the Florida Department of Health, prepare them for analysis, and conduct basic exploration of the demographic growth.\nSee the report in its native environment of suicide-prevention-2019 repository here\n\rEnvironment\r# Attach these packages so their functions don\u0026#39;t need to be qualified\r# see http://r-pkgs.had.co.nz/namespace.html#search-path\rlibrary(magrittr) #Pipes\rlibrary(ggplot2) # graphs\rlibrary(dplyr)\rrequireNamespace(\u0026quot;tidyr\u0026quot;) # data tidying\rrequireNamespace(\u0026quot;ggpubr\u0026quot;) # publication plots\rrequireNamespace(\u0026quot;readxl\u0026quot;) # data import\r\rData Wrangling\rData Origin\rThe initial extract of the data was obtained from www.flhealthcharts.com a reporting tool for population counts estimated by the Florida Department of Health. The figure below shows the modifications to the default query the produces the data product used in this demonstration:\nView of the reporting tool\n\rThe tool gives the option to save the product of the query as an Excel book (.xls), however, the import of this extension into R has been problematic, so I have converted (“save as”) the file manually into a more modern Excel format, .xlsx. This file is the raw source for the current report and can be dowloaded for closer inspection here.\n\rData import\rThe structure of the Excel file requires some tidying to enable a nimble analytic flow\nView of the extracted data\n\r# you will need to replace this path to the location where you stored your data file\rpath_file_input \u0026lt;- \u0026quot;./content/post/2020-03-27-florida-demographic-growth/data/FloridaPopulation.xlsx\u0026quot;\rds0 \u0026lt;- readxl::read_excel(path_file_input, col_names = FALSE, skip = 3)\r\rData Tweaking\rWe can identify several problems to address:\n1. Not all columns have names\n2. race, ethnicity, sex, and age_group are stored in merged spreadsheet cells\n3. Sums for categories are recorded in rows as observations (e.g Total)\n4. Some values of age_group are misinterpreted as dates (e.g. 1-4 becomes 4-Jan)\n5. age_group does not bin the population evenly (e.g. 20-24 vs 25-34)\nTweak 1\rTo address (1) we skipped the first 3 lines during import, and now need to assign the name of the columns manually:\nds1 \u0026lt;- ds0 # duplicate to preserve the original\r# because we removed the row with columns names during import:\rnames(ds1) \u0026lt;- c(\u0026quot;race\u0026quot;,\u0026quot;ethnicity\u0026quot;,\u0026quot;sex\u0026quot;,\u0026quot;age_group\u0026quot;,\u0026quot;age\u0026quot;,as.character(c(2006:2020)),\u0026quot;total\u0026quot;)\rds1 %\u0026gt;% dplyr::glimpse(90)\rObservations: 807\rVariables: 21\r$ race \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA...\r$ ethnicity \u0026lt;chr\u0026gt; \u0026quot;Hispanic\u0026quot;, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...\r$ sex \u0026lt;chr\u0026gt; \u0026quot;Female\u0026quot;, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...\r$ age_group \u0026lt;chr\u0026gt; \u0026quot;\u0026lt;1\u0026quot;, NA, \u0026quot;43834\u0026quot;, NA, NA, NA, NA, \u0026quot;43960\u0026quot;, NA, NA, NA, NA, NA, \u0026quot;44...\r$ age \u0026lt;chr\u0026gt; \u0026quot;0\u0026quot;, \u0026quot;Total\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;Total\u0026quot;, \u0026quot;5\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;7\u0026quot;, \u0026quot;8\u0026quot;, \u0026quot;9\u0026quot;,...\r$ `2006` \u0026lt;dbl\u0026gt; 33295, 33295, 24323, 24323, 24323, 24323, 97292, 25382, 25382, 2538...\r$ `2007` \u0026lt;dbl\u0026gt; 32276, 32276, 25841, 25841, 25841, 25841, 103364, 26712, 26712, 267...\r$ `2008` \u0026lt;dbl\u0026gt; 30429, 30429, 28693, 28693, 28693, 28693, 114772, 27637, 27637, 276...\r$ `2009` \u0026lt;dbl\u0026gt; 29468, 29468, 29927, 29919, 29917, 29853, 119616, 28378, 28378, 283...\r$ `2010` \u0026lt;dbl\u0026gt; 33976, 33976, 24145, 24145, 24145, 24145, 96580, 25981, 25943, 2594...\r$ `2011` \u0026lt;dbl\u0026gt; 27302, 27302, 27206, 27206, 27206, 27206, 108825, 26380, 26380, 263...\r$ `2012` \u0026lt;dbl\u0026gt; 26795, 26795, 27566, 27566, 27566, 27566, 110264, 26817, 26817, 268...\r$ `2013` \u0026lt;dbl\u0026gt; 27240, 27240, 27774, 27774, 27774, 27774, 111097, 27613, 27613, 276...\r$ `2014` \u0026lt;dbl\u0026gt; 28288, 28288, 27816, 27816, 27816, 27816, 111262, 28375, 28375, 283...\r$ `2015` \u0026lt;dbl\u0026gt; 29203, 29203, 28638, 28638, 28638, 28638, 114550, 28991, 28991, 289...\r$ `2016` \u0026lt;dbl\u0026gt; 29889, 29889, 29643, 29643, 29643, 29643, 118572, 29658, 29658, 296...\r$ `2017` \u0026lt;dbl\u0026gt; 30593, 30593, 30386, 30386, 30386, 30386, 121545, 30362, 30362, 303...\r$ `2018` \u0026lt;dbl\u0026gt; 30399, 30399, 31398, 31398, 31398, 31398, 125592, 31198, 31198, 311...\r$ `2019` \u0026lt;dbl\u0026gt; 31781, 31781, 31781, 31781, 31781, 31781, 127125, 31937, 31937, 319...\r$ `2020` \u0026lt;dbl\u0026gt; 32313, 32313, 32313, 32313, 32313, 32313, 129252, 32476, 32476, 324...\r$ total \u0026lt;dbl\u0026gt; 453247, 453247, 427450, 427442, 427440, 427376, 1709708, 427898, 42...\r# Note, we will create a separate name (e.g. `ds1`, `ds2`, `ds3`, etc) only for the dataframes #we intend to keep, otherwise we will overwrite the existing to augment with trivial changes\r\rTweak 2 and 3\rTo address (2) we apply tidyr::fill() which carries the observation forward until it encounters a non-empty cell. dplyr::filter addresses (3), removing observations that store total counts, while stringr::str_replace recodes values that got misinterpreted as dates.\nds1 \u0026lt;- ds1 %\u0026gt;%\r# carry observations forward to fill cells missing due to Excel structure ()\rtidyr::fill(race, ethnicity,sex,age_group, age) %\u0026gt;% dplyr::filter(!age == \u0026quot;Total\u0026quot;) # because makes data untidy, we\u0026#39;ll compute later\rds1 %\u0026gt;% dplyr::glimpse(90)\rObservations: 688\rVariables: 21\r$ race \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Whi...\r$ ethnicity \u0026lt;chr\u0026gt; \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispan...\r$ sex \u0026lt;chr\u0026gt; \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female...\r$ age_group \u0026lt;chr\u0026gt; \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;43834\u0026quot;, \u0026quot;43834\u0026quot;, \u0026quot;43834\u0026quot;, \u0026quot;43834\u0026quot;, \u0026quot;43960\u0026quot;, \u0026quot;43960\u0026quot;, \u0026quot;43960\u0026quot;...\r$ age \u0026lt;chr\u0026gt; \u0026quot;0\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;5\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;7\u0026quot;, \u0026quot;8\u0026quot;, \u0026quot;9\u0026quot;, \u0026quot;10\u0026quot;, \u0026quot;11\u0026quot;, \u0026quot;12\u0026quot;,...\r$ `2006` \u0026lt;dbl\u0026gt; 33295, 24323, 24323, 24323, 24323, 25382, 25382, 25382, 25382, 2538...\r$ `2007` \u0026lt;dbl\u0026gt; 32276, 25841, 25841, 25841, 25841, 26712, 26712, 26712, 26712, 2671...\r$ `2008` \u0026lt;dbl\u0026gt; 30429, 28693, 28693, 28693, 28693, 27637, 27637, 27637, 27637, 2763...\r$ `2009` \u0026lt;dbl\u0026gt; 29468, 29927, 29919, 29917, 29853, 28378, 28378, 28378, 28378, 2837...\r$ `2010` \u0026lt;dbl\u0026gt; 33976, 24145, 24145, 24145, 24145, 25981, 25943, 25943, 25914, 2591...\r$ `2011` \u0026lt;dbl\u0026gt; 27302, 27206, 27206, 27206, 27206, 26380, 26380, 26380, 26380, 2638...\r$ `2012` \u0026lt;dbl\u0026gt; 26795, 27566, 27566, 27566, 27566, 26817, 26817, 26817, 26817, 2681...\r$ `2013` \u0026lt;dbl\u0026gt; 27240, 27774, 27774, 27774, 27774, 27613, 27613, 27613, 27613, 2761...\r$ `2014` \u0026lt;dbl\u0026gt; 28288, 27816, 27816, 27816, 27816, 28375, 28375, 28375, 28375, 2837...\r$ `2015` \u0026lt;dbl\u0026gt; 29203, 28638, 28638, 28638, 28638, 28991, 28991, 28991, 28991, 2899...\r$ `2016` \u0026lt;dbl\u0026gt; 29889, 29643, 29643, 29643, 29643, 29658, 29658, 29658, 29658, 2965...\r$ `2017` \u0026lt;dbl\u0026gt; 30593, 30386, 30386, 30386, 30386, 30362, 30362, 30362, 30362, 3036...\r$ `2018` \u0026lt;dbl\u0026gt; 30399, 31398, 31398, 31398, 31398, 31198, 31198, 31198, 31198, 3119...\r$ `2019` \u0026lt;dbl\u0026gt; 31781, 31781, 31781, 31781, 31781, 31937, 31937, 31937, 31937, 3193...\r$ `2020` \u0026lt;dbl\u0026gt; 32313, 32313, 32313, 32313, 32313, 32476, 32476, 32476, 32476, 3247...\r$ total \u0026lt;dbl\u0026gt; 453247, 427450, 427442, 427440, 427376, 427898, 427860, 427860, 427...\r\rTweak 4\rWe need to do some investigation to address (4) and recode values that got misinterpreted as dates during the import\nds1 %\u0026gt;% dplyr::distinct(age_group) # to find out what strings got misinterpreted\r# A tibble: 13 x 1\rage_group\r\u0026lt;chr\u0026gt; 1 \u0026lt;1 2 43834 3 43960 4 44118 5 15-19 6 20-24 7 25-34 8 35-44 9 45-54 10 55-64 11 65-74 12 75-84 13 85+ \rds1 %\u0026gt;% dplyr::filter(age_group %in% c(\u0026quot;43834\u0026quot;,\u0026quot;43960\u0026quot;,\u0026quot;44118\u0026quot;)) %\u0026gt;% dplyr::distinct(age_group, age) # to identify how to recode\r# A tibble: 14 x 2\rage_group age \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;\r1 43834 1 2 43834 2 3 43834 3 4 43834 4 5 43960 5 6 43960 6 7 43960 7 8 43960 8 9 43960 9 10 44118 10 11 44118 11 12 44118 12 13 44118 13 14 44118 14 \r# imlement the recoding\rds1 \u0026lt;- ds1 %\u0026gt;% dplyr::mutate(\rage_group = stringr::str_replace(age_group, \u0026quot;43834\u0026quot;, \u0026quot;1-4\u0026quot;)\r,age_group = stringr::str_replace(age_group, \u0026quot;43960\u0026quot;, \u0026quot;5-9\u0026quot;)\r,age_group = stringr::str_replace(age_group, \u0026quot;44118\u0026quot;, \u0026quot;10-14\u0026quot;)\r) %\u0026gt;%\rdplyr::select(-total) # because it makes no sense in this context (adds up across the rows)\rds1 %\u0026gt;% glimpse(90)\rObservations: 688\rVariables: 20\r$ race \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Whi...\r$ ethnicity \u0026lt;chr\u0026gt; \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispan...\r$ sex \u0026lt;chr\u0026gt; \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female...\r$ age_group \u0026lt;chr\u0026gt; \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;1-4\u0026quot;, \u0026quot;1-4\u0026quot;, \u0026quot;1-4\u0026quot;, \u0026quot;1-4\u0026quot;, \u0026quot;5-9\u0026quot;, \u0026quot;5-9\u0026quot;, \u0026quot;5-9\u0026quot;, \u0026quot;5-9\u0026quot;, \u0026quot;5-9\u0026quot;...\r$ age \u0026lt;chr\u0026gt; \u0026quot;0\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;5\u0026quot;, \u0026quot;6\u0026quot;, \u0026quot;7\u0026quot;, \u0026quot;8\u0026quot;, \u0026quot;9\u0026quot;, \u0026quot;10\u0026quot;, \u0026quot;11\u0026quot;, \u0026quot;12\u0026quot;,...\r$ `2006` \u0026lt;dbl\u0026gt; 33295, 24323, 24323, 24323, 24323, 25382, 25382, 25382, 25382, 2538...\r$ `2007` \u0026lt;dbl\u0026gt; 32276, 25841, 25841, 25841, 25841, 26712, 26712, 26712, 26712, 2671...\r$ `2008` \u0026lt;dbl\u0026gt; 30429, 28693, 28693, 28693, 28693, 27637, 27637, 27637, 27637, 2763...\r$ `2009` \u0026lt;dbl\u0026gt; 29468, 29927, 29919, 29917, 29853, 28378, 28378, 28378, 28378, 2837...\r$ `2010` \u0026lt;dbl\u0026gt; 33976, 24145, 24145, 24145, 24145, 25981, 25943, 25943, 25914, 2591...\r$ `2011` \u0026lt;dbl\u0026gt; 27302, 27206, 27206, 27206, 27206, 26380, 26380, 26380, 26380, 2638...\r$ `2012` \u0026lt;dbl\u0026gt; 26795, 27566, 27566, 27566, 27566, 26817, 26817, 26817, 26817, 2681...\r$ `2013` \u0026lt;dbl\u0026gt; 27240, 27774, 27774, 27774, 27774, 27613, 27613, 27613, 27613, 2761...\r$ `2014` \u0026lt;dbl\u0026gt; 28288, 27816, 27816, 27816, 27816, 28375, 28375, 28375, 28375, 2837...\r$ `2015` \u0026lt;dbl\u0026gt; 29203, 28638, 28638, 28638, 28638, 28991, 28991, 28991, 28991, 2899...\r$ `2016` \u0026lt;dbl\u0026gt; 29889, 29643, 29643, 29643, 29643, 29658, 29658, 29658, 29658, 2965...\r$ `2017` \u0026lt;dbl\u0026gt; 30593, 30386, 30386, 30386, 30386, 30362, 30362, 30362, 30362, 3036...\r$ `2018` \u0026lt;dbl\u0026gt; 30399, 31398, 31398, 31398, 31398, 31198, 31198, 31198, 31198, 3119...\r$ `2019` \u0026lt;dbl\u0026gt; 31781, 31781, 31781, 31781, 31781, 31937, 31937, 31937, 31937, 3193...\r$ `2020` \u0026lt;dbl\u0026gt; 32313, 32313, 32313, 32313, 32313, 32476, 32476, 32476, 32476, 3247...\r\rTweak 5\rNow we need to recode the values of age into a new grouping variable age_group5, which will correct the unevennes of the original grouping in age_group\nds1$age_group5 \u0026lt;- ds1$age_group # because we want to keep the original for quality check\rds1$age_group5[ds1$age %in% c(0:4)] \u0026lt;- \u0026quot;0-4\u0026quot;\rds1$age_group5[ds1$age %in% c(25:29)] \u0026lt;- \u0026quot;25-29\u0026quot;\rds1$age_group5[ds1$age %in% c(30:34)] \u0026lt;- \u0026quot;30-34\u0026quot;\rds1$age_group5[ds1$age %in% c(35:39)] \u0026lt;- \u0026quot;35-39\u0026quot;\rds1$age_group5[ds1$age %in% c(40:44)] \u0026lt;- \u0026quot;40-44\u0026quot;\rds1$age_group5[ds1$age %in% c(45:49)] \u0026lt;- \u0026quot;45-49\u0026quot;\rds1$age_group5[ds1$age %in% c(50:54)] \u0026lt;- \u0026quot;50-54\u0026quot;\rds1$age_group5[ds1$age %in% c(55:59)] \u0026lt;- \u0026quot;55-59\u0026quot;\rds1$age_group5[ds1$age %in% c(60:64)] \u0026lt;- \u0026quot;60-64\u0026quot;\rds1$age_group5[ds1$age %in% c(65:69)] \u0026lt;- \u0026quot;65-69\u0026quot;\rds1$age_group5[ds1$age %in% c(70:74)] \u0026lt;- \u0026quot;70-74\u0026quot;\rds1$age_group5[ds1$age %in% c(75:79)] \u0026lt;- \u0026quot;75-79\u0026quot;\rds1$age_group5[ds1$age %in% c(80:84)] \u0026lt;- \u0026quot;80-84\u0026quot;\rds1 %\u0026gt;% dplyr::distinct(age_group, age_group5) # to inspect the result\r# A tibble: 19 x 2\rage_group age_group5\r\u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; 1 \u0026lt;1 0-4 2 1-4 0-4 3 5-9 5-9 4 10-14 10-14 5 15-19 15-19 6 20-24 20-24 7 25-34 25-29 8 25-34 30-34 9 35-44 35-39 10 35-44 40-44 11 45-54 45-49 12 45-54 50-54 13 55-64 55-59 14 55-64 60-64 15 65-74 65-69 16 65-74 70-74 17 75-84 75-79 18 75-84 80-84 19 85+ 85+ \r\rPivot Long\rTo enable a more seemless graph making, as well as to provide a more convenient shape for subsequent aggregation over age groups, we need to tidyr:pivot_long (formely known as tidyr::gather) the columns storing population estimates for each year.\n# to translate into a longer form with respect to year\rds2 \u0026lt;- ds1 %\u0026gt;%\rtidyr::pivot_longer(cols = as.character(2006:2020),names_to = \u0026quot;year\u0026quot;, values_to = \u0026quot;count\u0026quot;) ds2 %\u0026gt;% dplyr::glimpse(90)\rObservations: 10,320\rVariables: 8\r$ race \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Wh...\r$ ethnicity \u0026lt;chr\u0026gt; \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispanic\u0026quot;, \u0026quot;Hispa...\r$ sex \u0026lt;chr\u0026gt; \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Femal...\r$ age_group \u0026lt;chr\u0026gt; \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, \u0026quot;\u0026lt;1\u0026quot;, ...\r$ age \u0026lt;chr\u0026gt; \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;...\r$ age_group5 \u0026lt;chr\u0026gt; \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-4\u0026quot;, \u0026quot;0-...\r$ year \u0026lt;chr\u0026gt; \u0026quot;2006\u0026quot;, \u0026quot;2007\u0026quot;, \u0026quot;2008\u0026quot;, \u0026quot;2009\u0026quot;, \u0026quot;2010\u0026quot;, \u0026quot;2011\u0026quot;, \u0026quot;2012\u0026quot;, \u0026quot;2013\u0026quot;, \u0026quot;2...\r$ count \u0026lt;dbl\u0026gt; 33295, 32276, 30429, 29468, 33976, 27302, 26795, 27240, 28288, 292...\r# `ds2` is the source set for computing totals because it has both `age_group`` categories\r\rFactors\rBefore aggregating over age_group and age_group5 let us transform string variables into factors. so that we don’t have to do it in the individual data sets.\nlvl_age_groups \u0026lt;-c(\r\u0026quot;\u0026lt;1\u0026quot;\r,\u0026quot;1-4\u0026quot;\r,\u0026quot;5-9\u0026quot;\r,\u0026quot;10-14\u0026quot;\r,\u0026quot;15-19\u0026quot;\r,\u0026quot;20-24\u0026quot;\r,\u0026quot;25-34\u0026quot;\r,\u0026quot;35-44\u0026quot;\r,\u0026quot;45-54\u0026quot;\r,\u0026quot;55-64\u0026quot;\r,\u0026quot;65-74\u0026quot;\r,\u0026quot;75-84\u0026quot;\r,\u0026quot;85+\u0026quot;\r)\rlvl_age_groups5 \u0026lt;- c(\r\u0026quot;0-4\u0026quot;\r,\u0026quot;5-9\u0026quot;\r,\u0026quot;10-14\u0026quot;\r,\u0026quot;15-19\u0026quot;\r,\u0026quot;20-24\u0026quot;\r,\u0026quot;25-29\u0026quot;\r,\u0026quot;30-34\u0026quot;\r,\u0026quot;35-39\u0026quot;\r,\u0026quot;40-44\u0026quot;\r,\u0026quot;45-49\u0026quot;\r,\u0026quot;50-54\u0026quot;\r,\u0026quot;55-59\u0026quot;\r,\u0026quot;60-64\u0026quot;\r,\u0026quot;65-69\u0026quot;\r,\u0026quot;70-74\u0026quot;\r,\u0026quot;75-79\u0026quot;\r,\u0026quot;80-84\u0026quot;\r,\u0026quot;85+\u0026quot;\r)\rds2 \u0026lt;- ds2 %\u0026gt;%\rdplyr::mutate(\rrace_ethnicity = factor(paste0(race, \u0026quot; + \u0026quot;, ethnicity))\r,race = factor(race)\r,ethnicity = factor(ethnicity)\r,age_group = factor(age_group, levels = lvl_age_groups)\r,age_group5 = factor(age_group5, levels = lvl_age_groups5)\r,age = as.integer(age)\r,sex = factor(sex)\r,year = as.integer(year)\r) %\u0026gt;% dplyr::select(race, ethnicity, age_group, age_group5, dplyr::everything())\rds2 %\u0026gt;% dplyr::glimpse(90)\rObservations: 10,320\rVariables: 9\r$ race \u0026lt;fct\u0026gt; White, White, White, White, White, White, White, White, White,...\r$ ethnicity \u0026lt;fct\u0026gt; Hispanic, Hispanic, Hispanic, Hispanic, Hispanic, Hispanic, Hi...\r$ age_group \u0026lt;fct\u0026gt; \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, \u0026lt;1, 1-...\r$ age_group5 \u0026lt;fct\u0026gt; 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-4, 0-...\r$ sex \u0026lt;fct\u0026gt; Female, Female, Female, Female, Female, Female, Female, Female...\r$ age \u0026lt;int\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,...\r$ year \u0026lt;int\u0026gt; 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 20...\r$ count \u0026lt;dbl\u0026gt; 33295, 32276, 30429, 29468, 33976, 27302, 26795, 27240, 28288,...\r$ race_ethnicity \u0026lt;fct\u0026gt; White + Hispanic, White + Hispanic, White + Hispanic, White + ...\r\rAggregate\rNote that at this point, each row contains a population estimate for a given age in years. However, as you might have noticed that counts for each year of age are not unique:\nds2 %\u0026gt;% dplyr::filter(\rage %in% c(25:39), race_ethnicity == \u0026quot;White + Hispanic\u0026quot;,sex == \u0026quot;Female\u0026quot;, year==2018\r) %\u0026gt;% dplyr::select(race, ethnicity, age_group, age_group5, sex, age,count)\r# A tibble: 15 x 7\rrace ethnicity age_group age_group5 sex age count\r\u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r1 White Hispanic 25-34 25-29 Female 25 34479\r2 White Hispanic 25-34 25-29 Female 26 34479\r3 White Hispanic 25-34 25-29 Female 27 34479\r4 White Hispanic 25-34 25-29 Female 28 34479\r5 White Hispanic 25-34 25-29 Female 29 34479\r6 White Hispanic 25-34 30-34 Female 30 35056\r7 White Hispanic 25-34 30-34 Female 31 35056\r8 White Hispanic 25-34 30-34 Female 32 35056\r9 White Hispanic 25-34 30-34 Female 33 35056\r10 White Hispanic 25-34 30-34 Female 34 35056\r11 White Hispanic 35-44 35-39 Female 35 36549\r12 White Hispanic 35-44 35-39 Female 36 36549\r13 White Hispanic 35-44 35-39 Female 37 36549\r14 White Hispanic 35-44 35-39 Female 38 36549\r15 White Hispanic 35-44 35-39 Female 39 36549\rIn fact, it appears that Florida Health Charts computes the total for 5-year category and then devides it evenly among constituent elements of the age_category. My guess, this deals with privacy guidelines. Therefore, the most granualar age break up is only 5-year categories.\nTo preserve the original grouping we create two separate datasets, each providing the totals for respective age category.\nds_age_group \u0026lt;- ds2 %\u0026gt;% dplyr::group_by(race, ethnicity, sex, age_group, year) %\u0026gt;% dplyr::summarize(\rcount = sum(count, na.rm = T)\r) %\u0026gt;% dplyr::ungroup() %\u0026gt;% dplyr::mutate(\rrace_ethnicity = paste0(race, \u0026quot; + \u0026quot;, ethnicity),\rrace_ethnicity = factor(race_ethnicity)\r)\rds_age_group5 \u0026lt;- ds2 %\u0026gt;% dplyr::group_by(race, ethnicity, sex, age_group5, year) %\u0026gt;% dplyr::summarize(\rcount = sum(count, na.rm = T)\r) %\u0026gt;% dplyr::ungroup() %\u0026gt;% dplyr::mutate(\rrace_ethnicity = paste0(race, \u0026quot; + \u0026quot;, ethnicity),\rrace_ethnicity = factor(race_ethnicity)\r)\rIt is the ds_age_group5 that will be focus of subsequent graphs. However, to better demonstrate why we needed to create new grouping of ages, we will preserve both dataframes.\n\r\rSave to disk\rlist(\r\u0026quot;ds_wide\u0026quot; = ds1\r,\u0026quot;ds_long\u0026quot; = ds2\r,\u0026quot;ds_age_group\u0026quot; = ds_age_group\r,\u0026quot;ds_age_group3\u0026quot; = ds_age_group5\r) %\u0026gt;% saveRDS(\u0026quot;./content/post/2020-03-27-florida-demographic-growth/data/clean_data.rds\u0026quot;)\rThe cleaned version of this dataset is available for download here.\n\r\rGraphing\rTotal population\r\rHow does the total population of Florida changes between 2006 and 2020?\n\r# Total population of Florida over the years\rds_age_group5 %\u0026gt;% dplyr::group_by(year) %\u0026gt;% dplyr::summarize(\rcount = sum(count, na.rm = T)\r) %\u0026gt;% ggplot(aes(x=year, y = count))+\rgeom_point()+\rgeom_line()+\rscale_y_continuous(labels = scales::comma)+\rtheme_bw()\r\rEthnic groups: Together\r\rHow does each ethnic group change during this time?\n\r# total population of Florida by broken down by 4 ethnic groups (race_ethnicity)\rd1 \u0026lt;- ds_age_group5 %\u0026gt;% dplyr::group_by(race_ethnicity, year) %\u0026gt;% dplyr::summarize(\rn_people = sum(count, rm.na = T)\r)\rg1 \u0026lt;- d1 %\u0026gt;% ggplot(aes(x = year, y = n_people, color = race_ethnicity))+\rgeom_line(aes(group = race_ethnicity))+\rgeom_point(shape = 21, fill = NA, size =2)+\rscale_y_continuous(labels = scales::comma)+\rtheme_bw()+\rtheme(\raxis.text.x = element_text(angle = - 90,vjust =.5, hjust = -0)\r#https://stackoverflow.com/questions/1330989/rotating-and-spacing-axis-labels-in-ggplot2\r)+\rlabs(\rtitle = \u0026quot;Population growth in Florida over last 15 years \\n broken down by ethnic groups\u0026quot;\r,color = \u0026quot;Ethnic Group\u0026quot;\r,x = \u0026quot;Calendar Year\u0026quot;\r,y = \u0026quot;Population Count\u0026quot;\r)\rg1\r\rEthnic groups: Separate\r\rwhat Ethnic group is most dissimilar from the other three in their dynamics?\n\r# Q: what Ethnic group is most dissimilar from the other three in their dynamics?\rg1 + facet_wrap(~race_ethnicity, scale = \u0026quot;free_y\u0026quot;)\r# A: \u0026quot;White + Non-Hispanic\u0026quot; because of a \u0026quot;dip\u0026quot; in late 2000\u0026#39;s\r\rAge composition in 2019\r\rWhat is the age composition of each ethnic group in 2019?\n\r# Build a graph showing age composition of all ethnic groups in 2019\rg2 \u0026lt;- ds_age_group5 %\u0026gt;%\rdplyr::filter(year == 2019) %\u0026gt;%\rggplot(aes(x = age_group5, y = count, fill = race_ethnicity)) +\rgeom_col()+\rfacet_grid(sex ~ race_ethnicity)+\rscale_y_continuous(labels = scales::comma)+\r# https://stackoverflow.com/questions/14563989/force-r-to-stop-plotting-abbreviated-axis-labels-e-g-1e00-in-ggplot2 also https://r-graphics.org/recipe-axes-tick-label\rtheme_bw()+\rtheme(\raxis.text.x = element_text(angle = - 90,vjust =.5, hjust = -0)\r#https://stackoverflow.com/questions/1330989/rotating-and-spacing-axis-labels-in-ggplot2\r)+\rlabs(\rtitle = \u0026quot;Population in Florida in 2019 broken down by age groups and gender\u0026quot;\r,color = \u0026quot;Ethnic Group\u0026quot;\r,x = \u0026quot;Calendar Year\u0026quot;\r,y = \u0026quot;Population Count\u0026quot;\r)\rg2\r\rWhat would it look like if we used the original age_group?\n\rg2a \u0026lt;- ds_age_group %\u0026gt;%\rdplyr::filter(year == 2019) %\u0026gt;%\rggplot(aes(x = age_group, y = count, fill = race_ethnicity)) +\rgeom_col()+\rfacet_grid(sex ~ race_ethnicity)+\rscale_y_continuous(labels = scales::comma)+\r# https://stackoverflow.com/questions/14563989/force-r-to-stop-plotting-abbreviated-axis-labels-e-g-1e00-in-ggplot2 also https://r-graphics.org/recipe-axes-tick-label\rtheme_bw()+\rtheme(\raxis.text.x = element_text(angle = - 90,vjust =.5, hjust = -0)\r#https://stackoverflow.com/questions/1330989/rotating-and-spacing-axis-labels-in-ggplot2\r)+\rlabs(\rtitle = \u0026quot;Population in Florida in 2019 broken down by age groups and gender\u0026quot;\r,color = \u0026quot;Ethnic Group\u0026quot;\r,x = \u0026quot;Calendar Year\u0026quot;\r,y = \u0026quot;Population Count\u0026quot;\r)\rg2a\r\r\rsession information\rFor the sake of documentation and reproducibility, the current report was rendered in the following environment. Click the line below to expand.\n\rEnvironment \n- Session info -------------------------------------------------------------------------------------------------------\rsetting value version R version 3.6.2 (2019-12-12)\ros Windows 10 x64 system x86_64, mingw32 ui RTerm language (EN) collate English_United States.1252 ctype English_United States.1252 tz America/New_York date 2020-03-29 - Packages -----------------------------------------------------------------------------------------------------------\rpackage * version date lib source assertthat 0.2.1 2019-03-21 [1] CRAN (R 3.6.2)\rbackports 1.1.5 2019-10-02 [1] CRAN (R 3.6.1)\rblogdown 0.17 2019-11-13 [1] CRAN (R 3.6.2)\rbookdown 0.17 2020-01-11 [1] CRAN (R 3.6.2)\rcallr 3.4.2 2020-02-12 [1] CRAN (R 3.6.2)\rcellranger 1.1.0 2016-07-27 [1] CRAN (R 3.6.2)\rcli 2.0.1 2020-01-08 [1] CRAN (R 3.6.2)\rcolorspace 1.4-1 2019-03-18 [1] CRAN (R 3.6.1)\rcrayon 1.3.4 2017-09-16 [1] CRAN (R 3.6.2)\rdesc 1.2.0 2018-05-01 [1] CRAN (R 3.6.2)\rdevtools 2.2.2 2020-02-17 [1] CRAN (R 3.6.3)\rdigest 0.6.24 2020-02-12 [1] CRAN (R 3.6.2)\rdplyr * 0.8.4 2020-01-31 [1] CRAN (R 3.6.2)\rellipsis 0.3.0 2019-09-20 [1] CRAN (R 3.6.2)\revaluate 0.14 2019-05-28 [1] CRAN (R 3.6.2)\rfansi 0.4.1 2020-01-08 [1] CRAN (R 3.6.2)\rfs 1.3.1 2019-05-06 [1] CRAN (R 3.6.2)\rggplot2 * 3.2.1 2019-08-10 [1] CRAN (R 3.6.2)\rggpubr 0.2.5 2020-02-13 [1] CRAN (R 3.6.2)\rggsignif 0.6.0 2019-08-08 [1] CRAN (R 3.6.2)\rglue 1.3.1 2019-03-12 [1] CRAN (R 3.6.2)\rgtable 0.3.0 2019-03-25 [1] CRAN (R 3.6.2)\rhtmltools 0.4.0 2019-10-04 [1] CRAN (R 3.6.2)\rknitr * 1.28 2020-02-06 [1] CRAN (R 3.6.2)\rlazyeval 0.2.2 2019-03-15 [1] CRAN (R 3.6.2)\rlifecycle 0.1.0 2019-08-01 [1] CRAN (R 3.6.2)\rmagrittr * 1.5 2014-11-22 [1] CRAN (R 3.6.2)\rmemoise 1.1.0 2017-04-21 [1] CRAN (R 3.6.2)\rmunsell 0.5.0 2018-06-12 [1] CRAN (R 3.6.2)\rpillar 1.4.3 2019-12-20 [1] CRAN (R 3.6.2)\rpkgbuild 1.0.6 2019-10-09 [1] CRAN (R 3.6.2)\rpkgconfig 2.0.3 2019-09-22 [1] CRAN (R 3.6.2)\rpkgload 1.0.2 2018-10-29 [1] CRAN (R 3.6.2)\rprettyunits 1.1.1 2020-01-24 [1] CRAN (R 3.6.2)\rprocessx 3.4.2 2020-02-09 [1] CRAN (R 3.6.2)\rps 1.3.2 2020-02-13 [1] CRAN (R 3.6.2)\rpurrr 0.3.3 2019-10-18 [1] CRAN (R 3.6.2)\rR6 2.4.1 2019-11-12 [1] CRAN (R 3.6.2)\rRcpp 1.0.3 2019-11-08 [1] CRAN (R 3.6.2)\rreadxl 1.3.1 2019-03-13 [1] CRAN (R 3.6.2)\rremotes 2.1.1 2020-02-15 [1] CRAN (R 3.6.2)\rrlang 0.4.4 2020-01-28 [1] CRAN (R 3.6.2)\rrmarkdown 2.1 2020-01-20 [1] CRAN (R 3.6.2)\rrprojroot 1.3-2 2018-01-03 [1] CRAN (R 3.6.2)\rscales 1.1.0 2019-11-18 [1] CRAN (R 3.6.2)\rsessioninfo 1.1.1 2018-11-05 [1] CRAN (R 3.6.2)\rstringi 1.4.5 2020-01-11 [1] CRAN (R 3.6.2)\rstringr 1.4.0 2019-02-10 [1] CRAN (R 3.6.2)\rtestthat 2.3.1 2019-12-01 [1] CRAN (R 3.6.2)\rtibble 2.1.3 2019-06-06 [1] CRAN (R 3.6.2)\rtidyr 1.0.2 2020-01-24 [1] CRAN (R 3.6.2)\rtidyselect 1.0.0 2020-01-27 [1] CRAN (R 3.6.2)\rusethis 1.5.1 2019-07-04 [1] CRAN (R 3.6.2)\rutf8 1.1.4 2018-05-24 [1] CRAN (R 3.6.2)\rvctrs 0.2.2 2020-01-24 [1] CRAN (R 3.6.2)\rwithr 2.1.2 2018-03-15 [1] CRAN (R 3.6.2)\rxfun 0.12 2020-01-13 [1] CRAN (R 3.6.2)\ryaml 2.2.1 2020-02-01 [1] CRAN (R 3.6.2)\r[1] C:/Users/an499583/Documents/R/win-library/3.6\r[2] C:/Program Files/R/R-3.6.2/library\r\r","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585267200,"objectID":"773405c78b6c2e444929ed6de567e072","permalink":"/post/2020-03-27-florida-demographic-growth/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/post/2020-03-27-florida-demographic-growth/","section":"post","summary":"This blogposts shows how to extract population estimates data reported by the Florida Department of Health, prepare them for analysis, and conduct basic exploration of the demographic growth","tags":["demography","Florida"],"title":"Florida Demographic Growth","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","analytic workflow","graph making"],"content":"\r\rRecently I was invited to give a workshop on data analysis with R at the training retreat for Health System Impact Fellowship by Canadian Institutes of Health Research.\n#CIHR_ImpactFellows immersed in a hands-on RStudio workshop, led by @andkovpro, Assistant Prof @ UCF and alumnus of the 2017 fellow cohort. Thank you @andkovpro ! #HSIF2019 #enrichedcorecomps #datascience pic.twitter.com/P0Qp3saMQF\n\u0026mdash; Meghan McMahon (@McMahon_Meg) November 26, 2019  The workshop was hosted at the picturesque Hart House of the University of Toronto:\nThe workshop involved\nAudience\rMy audience constisted of postdoctoral researchers and Ph.D. students, few of whom had experience with R, however majority have taken 3 or more courses in statistics and applied analysis. To gain better understanding of their background, I have asked them to fill out a brief survey (see results in my slides)\nI had about 90 minutes, so I reasoned that instead of overwhelming them with technical information, which would leave little trace in their fatigued minds ( workshop was at the end of the day), I should create a resource that they would be able to use in the future. The time in workshop, then, should spent on gentle introduction to data analysis with R using the examples from this resource. This also gave my workshop the flexibility to accomodate learners of various skill levels: more advanced participants will have the material to study on their own if the talk leaves them underchallenged in any given point in time.\n\rLearning Objectives\rI wanted the audience to be exposed to examples of performing the following tasks:\nOrganizing data analysis in a RMarkdown document\n\rGraphing the predictions of a statistical model (logistic regression)\n\rJump-starting an analytic project using a project template\r\r\rDeliverables\r1. Organizing data analysis in a RMarkdown document\rI have created two reports, containing identidcal code that implemented basic exploration of Titanic data with logistic regression:\r- notebook-only - a notebook combining code and annotation in the same .Rmd file\r- separate-layers - a report separating the analytic layer (.R) from the annotation layer (.Rmd)\n\rpresentation slides\r\r\rGraphing a model\rCarefull not to overwhelm with details, I chose to focus on a basic logistic regression model predicting survival in the Titanic data.\n# Model 0\rsurvived ~ sex\r# Model 1\rsurvived ~ sex + age\r# Model 2\rsurvived ~ sex + age + passenger_class\r# Model 3\rsurvived ~ sex + age + passenger_class + port_embarked\r\rHowever, instead of focusing on interpreting the estimated parameters, I opted to generate predicted values and then to graph them to examine the effect respective variables would have on the binary outcome. We converted the log-odds into probabilities of the outcome (y-axis) and then mapped predictors on other visual dimension. To illustrate, the prediction for Model 2 survived ~ sex + age + passenger_class looked like this:\nmodel_2\n\r\rMaterials\r\rnotebook-only - analytic report as a notebook (combines code and annotation in the same .Rmd file)\rseparate-layers - analytic report separating the analytic layer (.R) from the annotation layer (.Rmd)\rpresentation slides\r\r\rAbstract\rThe workshop will review best practices of reproducible research including folder architecture, data preparation, graph making, statistical modeling, and script documentation. The workshop is targeted at researchers who are expected to conduct their own analysis of data and prepare reports that deliver the findings to both technical and executive audiences within health systems. Using logistic regression as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results.\n\r\r","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579996800,"objectID":"761f5d74c6a782b0825829cbd4f5a4b9","permalink":"/post/2020-01-07-graphing-models-with-titanic-data/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/post/2020-01-07-graphing-models-with-titanic-data/","section":"post","summary":"Recent example of 1) interpreting models through graphs rather than parameters 2) using self-contains RMarkdown notebook vs .R + .Rmd split  ","tags":["logistic regression","ggplot2"],"title":"Managing Data Analysis with RStudio","type":"post"},{"authors":["Andriy Koval"],"categories":["reproducible research","workflow","tidyverse"],"content":"\rMaterials\r\rnotebook-only - analytic report as a notebook (combines code and annotation in the same .Rmd file)\rseparate-layers - analytic report separating the analytic layer (.R) from the annotation layer (.Rmd)\rpresentation slides\r\r\rAbstract\rThe workshop will review best practices of reproducible research including folder architecture, data preparation, graph making, statistical modeling, and script documentation. The workshop is targeted at researchers who are expected to conduct their own analysis of data and prepare reports that deliver the findings to both technical and executive audiences within health systems. Using logistic regression as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results.\n\r","date":1574726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574899200,"objectID":"65bb67c0c9ba86af60e8a74819bda0d2","permalink":"/talk/2019-11-26-hsif-toronto-workshop/","publishdate":"2019-11-26T00:00:00Z","relpermalink":"/talk/2019-11-26-hsif-toronto-workshop/","section":"talk","summary":"The workshop introduces R and RStudio and makes the case for project-oriented workflows for applied data analysis. Using logistic regression on Titanic data as an example, the participants will learn to communicate statistical findings more effectively, and will evaluate the advantages of using computational notebooks in RStudio to disseminate the results","tags":["logistic regression","ggplot2"],"title":"Managing Data Analysis with RStudio","type":"talk"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rVisualising results of statistical modeling is a key component of data science workflow. Statistical graphs often is the best means to explain and promote research findings. However,in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives? This talk will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon.\nThe system evaluates synthetic socioeconomic and mortality data with logistic regression. The data was prepared for the hackathon by Statistic Canada and represents Canadian population. First, I will introduce a visualisation technique that uses color to create a meaningful expectations from the results of a logistic regression. Then I will discuss the workflow of the project that implements this graphing system ( github.com/andkov/ipdln-2018-hackathon ). I will conclude by building the case to prefer reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\n","date":1572998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573084800,"objectID":"870a87a076b3aa5ab823c99fd4e733a1","permalink":"/talk/2019-11-08-visualizing-logistic-regression/","publishdate":"2019-11-06T00:00:00Z","relpermalink":"/talk/2019-11-08-visualizing-logistic-regression/","section":"talk","summary":"Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs often is the best means to explain and promote research findings. However,in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?","tags":["logistic regression","ggplot2","coloring book","graphing techniques","hackathon"],"title":"Implementing Reproducible Visualizations","type":"talk"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics","Mental Health \u0026 Substance Use","Reproducible Research"],"content":"\rThis report demonstrate what disappears from the view of service utilization analysts when only Emergency and Acute Care data are mined from the EHR, a common practice in health services research. We study the cohort of 4,067 residents of Vancouver Island with severe alcohol addiction. Engagement with the cross-continuum terrain of services is aggraged over 10 years (2007 - 2017) and reported via categories of the Clinical Context Coding Scheme of the Vancouver Island Health Authority.\nRead the full report\nPlay with the pivot of results\nFigure 1: Aggregate cohort engagement of service classes: acute (red) and community (grey)\n\r","date":1564704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564704000,"objectID":"5a9eed4157a906826d635e4a6b1e3403","permalink":"/post/2019-08-01-what-lies-beyond-acute-care/","publishdate":"2019-08-02T00:00:00Z","relpermalink":"/post/2019-08-01-what-lies-beyond-acute-care/","section":"post","summary":"Using service utilization data of 4,067 residents of Vancouver Island with sever alcohol addiction we demonstrate the cross-continuum terrain of health services in Vancouver Island Health Authority.","tags":["electronic health records","heavy addiction","alcohol","substance abuse","health service utilization"],"title":"What Lies Beyond Acute Care Data","type":"post"},{"authors":[],"categories":[],"content":"\rI am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr. Andrea Piccinin and Dr. Scott Hofer. With IALSA, I worked on developing reproducible analytics (R + GitHub) for remote collaboration, particularly for implementing coordinated statistical analyses among multiple longitudinal studies of aging via remote participation.\nInterest in data-driven narratives of human aging lead me to explore the use of electronic health records (EHR) for research and improvement of patient care. Since October 2015 I have been working with Dr. Kenneth Moselle, the director of the Applied Clinical Research Unit (ACRU) of Vancouver Island Health Authority (VIHA) on curating the transformation of VIHA’s EHR into analyzable form and creating opportunities for academic and clinical researchers to work with these data in responsible and reproducible way. Together with Dr. Moselle I have launched a Data Science Studio at the University of Victoria, a research unit at the Institute on Aging and Lifelong Health dedicated to supporting its research affiliates and UVic students in accessing, handling, and modeling cross-continuum health records of VIHA.\nAt ACRU I worked on bridging healthcare data to analytic capacities of longitudinal modelling. My functions at ACRU included statistical and programming support for research and quality improvement projects, coordinating communication and empowering collaboration among three audiences: database managers, medical practitioners, and academic researchers. The overlap in my skills in statistical modeling, programming, and knowledge of VIHA’s electronic health records gave me a unique advantage to facilitate such a collaboration, the integrative nature of which offered great promises for improving patient care, medical science, and methodological practices of longitudinal research.\nIn August of 2017 I was awarded a CIHR Health System Impact Fellowship with BC Observatory for Population and Public Health of the BC Centre for Disease Control ($140,000 + $15,000 development fund). My program of work involved developing a system for population health surveillance that would focus on chronic diseases, with particular focus on mental health and substance use (MHSU) conditions, which tend to have high comorbidity rates, polysubstance use patterns, and slowly progressing pace of development. Drawing on my experience with EHR system employed by VIHA, I engaged various statistical modeling and learning techniques to construct analytic workflows capable of supporting clinical decisions at the point of service, while translating the acquired knowledge to be consumed by clinical stewards, system planners, and surveillance agencies.\nmindset\rData scientists describe the ultimate reality about data using various dialets of expression. Each translation has its benefits and disadvantages. We need them all to tell a good story.\nNo one language is better than the other. Each allows for different shades of distinction in model specification.\n\r","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561058495,"objectID":"b29fbe32d2b65a7f442839fc78fb3f21","permalink":"/post/academic-biography/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/academic-biography/","section":"post","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr.","tags":[],"title":"Academic Biography","type":"post"},{"authors":["Andriy Koval","Anthony Leamon","Kate Smolina"],"categories":["suppress-for-release"],"content":"\r\rPoster presented at the 2019 conference of the Canadian Association for Health Services and Policy Research, Halifax, Nova Scotia.\nNote: The number in parentheses (1) refers to the section of the poster.\nTake away points\r\rReproducible pipelines are hard, but they pay off\rThink of cognitive load first, computational load second\rInvest into dependency maps for (re-)learning forms \u0026amp; functions\rInvest into workflow maps for (re-)learning structures \u0026amp; processes\r\r\rBackground\rIn 2016, the Observatory for Population \u0026amp; Public Health of British Columbia launched the Chronic Disease Dashboard, an online reporting tool designed to address the gap in surveillance of chronic diseases. To protect against re-identification risks, the Ministry of Health required redacting small counts prior to releasing disease rates into public domain. These preparations, when conducted manually, have proven to be arduous, time consuming, and prone to human error.\n\rApproach\rWhile finding a “small” count (operationalized as “ \u0026lt; 5 ”) was straightforward, detecting conditions, in which suppressed values could be recalculated from related cells involved human judgement. As part of the embedded research by their Health System Impact Fellow (2017), the Observatory set out to automate this task, designing a reproducible workflow ( see section 5 of the poster ) that split data into disease-by-year data frames of a specific form ( 1 ), applied a sequence of logical tests ( 2 ) written to recognize conditions that made recalculation of suppressed values possible and printed a graph ( 6 ) for each case of suggested automatic redaction to be confirmed by a human ( 7 ).\n\rResults\rThe automated suppression was successfully integrated into the Dashboard maintenance. Data preparation, application of logical tests, and production of visual evidence were implemented in R and published as a version-controlled RStudio project on Github github.com/ihacru/suppress-for-release. A fully reproducible example with fictional data was made available to demonstrate the current logic of suppression and to ensure the availability of documentation for the future staff of the Observatory charged with Dashboard maintenance. To assist with learning, we designed a map of dependencies among the custom functions used for suppression ( 4 ) and illustrated their use in a simplified workflow ( 3 ), which allows studying the performance of logical tests before engaging the real data to applying the suppression logic ( 5 ) and to document the redaction decisions ( 7 ) Anticipating the evolution of suppression logic, we moduralized the logical tests ( 2 ) responsible for redaction and provided several options to vary the degree of preserved information ( blue vs light blue ).\n\rConclusions\rThis case of embedded research demonstrates the benefits and feasibility of integrating practices of reproducible analytics into routine workflow of epidemiological surveillance. We make a strong case for employing such learning devices as workflow maps ( 5 ) and function dependency trees ( 4 ) for structuring applied projects and ensuring their reproducibility.\n\r","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"1b96832744a02fc81fab3ac2a5a8410b","permalink":"/publication/koval-2018-severity-burden-mental-health/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/publication/koval-2018-severity-burden-mental-health/","section":"publication","summary":"Demonstrates the methods of suppressing small counts in a provincial surveillance system in preparation of data for public release.","tags":["small cell suppression","chronic disease surveillance","public health","reproducible research","ggplot2"],"title":"Suppressing Small Counts for Public Release","type":"publication"},{"authors":["Andriy Koval","Anthony Leamon","Kate Smolina"],"categories":["suppress-for-release"],"content":"\rPoster presented at the 2019 conference of the Canadian Association for Health Services and Policy Research, Halifax, Nova Scotia.\nNote: The number in parentheses (1) refers to the section of the poster.\nTake away points\r\rReproducible pipelines are hard, but they pay off\rThink of cognitive load first, computational load second\rInvest into dependency maps for (re-)learning forms \u0026amp; functions\rInvest into workflow maps for (re-)learning structures \u0026amp; processes\r\r\rBackground\rIn 2016, the Observatory for Population \u0026amp; Public Health of British Columbia launched the Chronic Disease Dashboard, an online reporting tool designed to address the gap in surveillance of chronic diseases. To protect against re-identification risks, the Ministry of Health required redacting small counts prior to releasing disease rates into public domain. These preparations, when conducted manually, have proven to be arduous, time consuming, and prone to human error.\n\rApproach\rWhile finding a “small” count (operationalized as “ \u0026lt; 5 ”) was straightforward, detecting conditions, in which suppressed values could be recalculated from related cells involved human judgement. As part of the embedded research by their Health System Impact Fellow (2017), the Observatory set out to automate this task, designing a reproducible workflow ( see section 5 of the poster ) that split data into disease-by-year data frames of a specific form ( 1 ), applied a sequence of logical tests ( 2 ) written to recognize conditions that made recalculation of suppressed values possible and printed a graph ( 6 ) for each case of suggested automatic redaction to be confirmed by a human ( 7 ).\n\rResults\rThe automated suppression was successfully integrated into the Dashboard maintenance. Data preparation, application of logical tests, and production of visual evidence were implemented in R and published as a version-controlled RStudio project on Github github.com/ihacru/suppress-for-release. A fully reproducible example with fictional data was made available to demonstrate the current logic of suppression and to ensure the availability of documentation for the future staff of the Observatory charged with Dashboard maintenance. To assist with learning, we designed a map of dependencies among the custom functions used for suppression ( 4 ) and illustrated their use in a simplified workflow ( 3 ), which allows studying the performance of logical tests before engaging the real data to applying the suppression logic ( 5 ) and to document the redaction decisions ( 7 ) Anticipating the evolution of suppression logic, we moduralized the logical tests ( 2 ) responsible for redaction and provided several options to vary the degree of preserved information ( blue vs light blue ).\n\rConclusions\rThis case of embedded research demonstrates the benefits and feasibility of integrating practices of reproducible analytics into routine workflow of epidemiological surveillance. We make a strong case for employing such learning devices as workflow maps ( 5 ) and function dependency trees ( 4 ) for structuring applied projects and ensuring their reproducibility.\n\r","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"68cee25142656a0448bc697f37c52ad4","permalink":"/publication/koval-2019-suppress-for-release/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/publication/koval-2019-suppress-for-release/","section":"publication","summary":"Demonstrates the methods of suppressing small counts in a provincial surveillance system in preparation of data for public release.","tags":["small cell suppression","chronic disease surveillance","public health","reproducible research","ggplot2"],"title":"Suppressing Small Counts for Public Release","type":"publication"},{"authors":["Emily C Duggan","Andrea M Piccinin","Sean Clouston","Andriy Koval","Annie Robitalle","Andrea R Zammit","Chenkai Wu","Cassandra L Brown","Lewina O Lee","Deborah Finkel","William H. Beasley","Jeffrey Kaye","Graciela Muniz Terrera","Mindy Katz","Richard B Lipton","Dorly Deeg","David A Bennett","Marcus Praetorius Björk","Boo Johansson","Avron Spiro II","Jennifer Weuve","Scott M Hofer"],"categories":["coordinated analysis","IALSA-Portland"],"content":"\rBackground\rSubstantial research is dedicated to understanding the aging-related dynamics among individual differences in level, change, and variation across physical and cognitive abilities. Evaluating replicability and synthesizing these findings has been limited by differences in measurements and samples, and by study design and statistical analyses confounding between-person differences with within-person changes. In this article, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.\n\rMethods\rWe performed coordinated analysis of bivariate growth models in data from 20,586 participants across eight longitudinal studies to examine individual differences in baseline level, rate of change, and occasion-specific variability in pulmonary and cognitive functioning. Results were summarized using meta-analysis.\n\rResults\rWe found consistent but weak baseline and longitudinal associations in levels of pulmonary and cognitive functioning, but no associations in occasion-specific variability.\n\rConclusions\rResults provide limited evidence for a consistent link between simultaneous changes in pulmonary and cognitive function in a normal aging population. Further research is required to understand patterns of onset of decline and differences in rates of change within and across physical and cognitive functioning domains, both within-individuals and across countries and birth cohorts. Coordinated analysis provides an efficient and rigorous approach for replicating and comparing results across independent longitudinal studies.\nSee more\n\r","date":1551484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551484800,"objectID":"50d7843ace7e770a5eb69bfc5db9ddb4","permalink":"/publication/duggan-2018-pulmonary-cognition-aging/","publishdate":"2019-03-02T00:00:00Z","relpermalink":"/publication/duggan-2018-pulmonary-cognition-aging/","section":"publication","summary":"In this second paper of a two-paper series, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.","tags":["pulmonary","cognition","cognitive aging","normative aging","longitudinal analysis"],"title":"A Multi-Study Coordinated Meta-Analysis of Pulmonary Function and Cognition in Aging","type":"publication"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rVisualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?\nThis presentation will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon. The system evaluates synthetic socioeconomic and mortality data with logistic regression. The data was prepared for the hackathon by Statistic Canada and represents Canadian population.\nTopics covered will include:\n\rIntroduction to a visualisation technique that uses color to create meaningful expectations from the results of a logistic regression.\rDetails related to the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon )\rBuilding the case for preference of reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\r\rVideo\r\r\r","date":1541113200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"010a0c32feb7228a67d237e138834c59","permalink":"/talk/2018-11-01-visualizing-logistic-regression/","publishdate":"2018-11-01T16:00:00-07:00","relpermalink":"/talk/2018-11-01-visualizing-logistic-regression/","section":"talk","summary":"Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?","tags":["logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"Visualizing Logistic Regression","type":"talk"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rAbstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software. First, I will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon, organized by Statistics Canada. The system evaluates synthetic socioeconomic and mortality data with logistic regression. Then I will discuss the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon ) and the RStudio + GitHub setup that hosts it. I will conclude by building the case to prefer reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\n\rTable of Content\rFigure 1\n\r\rLayers of Isolation\rFigure 2\n\r\r","date":1541023200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"9ad4009290131c1caf1cde78229fbc07","permalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","publishdate":"2018-10-31T15:00:00-07:00","relpermalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","section":"talk","summary":"Abstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software.","tags":["literate programming","computational essays","logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"When notebooks are not enough","type":"talk"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics"],"content":"\rPoster presented at the 2018 conference of the International Population Data Linkage Association, Banff, Alberta.\n","date":1537660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537660800,"objectID":"ade67b61c6a9760a8540d24f99cd88fb","permalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","publishdate":"2018-09-23T00:00:00Z","relpermalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","section":"publication","summary":"Demonstrates how cross-continuum terrain of health services can be described in with flexible classification scheme.","tags":["cccs"],"title":"Clinical Context Coding Scheme","type":"publication"},{"authors":["Amanda Kelly","Matthew Calamia","Andriy Koval","Graciela Muniz-Terrera","Andrea M.Piccinin","Sean Clouston","Linda B.Hassing","David A. Bennett","Boo Johansson","Scott M.Hofer"],"categories":["coordinated analysis"],"content":"\r","date":1456358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456358400,"objectID":"3445af2e990ad454352aed5822303af0","permalink":"/publication/kelly-2016-hypertension-diabetes-memory/","publishdate":"2016-02-25T00:00:00Z","relpermalink":"/publication/kelly-2016-hypertension-diabetes-memory/","section":"publication","summary":"The study explored the effects of living with Hypertension and Diabetes Mellitus on declarative memory performace using data from longitudinal studies from England, Sweden, and the United States.","tags":["cognition","cognitive aging","diabetes","hypertension","longitudinal analysis"],"title":"Independent and Interactive Impacts of Hypertension and Diabetes Mellitus on Verbal Memory","type":"publication"},{"authors":["Andriy Koval"],"categories":["reproducible research"],"content":"\rThe lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.\nOf specific importance is the data grooming stage, which enables a productive exploration of the data and establishes custody chains to support research conclusions based on the analytic products.\n","date":1412899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412899200,"objectID":"d2d2d10b1433ca923ab615ade69d4d28","permalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","publishdate":"2014-10-10T00:00:00Z","relpermalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","section":"talk","summary":"The lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.","tags":["data science","analytic workflow","dynamic documentation","computational essays"],"title":"Toolbox and Toolsets of Reproducible Research","type":"talk"}]