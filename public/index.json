[{"authors":["admin"],"categories":null,"content":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV\n","date":1559088000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1559088000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging. I subscribe to aspirations of open science and reproducible research.\nRead my academic biography.\nSee my work on github at /andkov\nDownload my CV","tags":null,"title":"Andriy Koval","type":"authors"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics","Mental Health \u0026 Substance Use","Reproducible Research"],"content":"\rThis report demonstrate what disappears from the view of service utilization analysts when only Emergency and Acute Care data are mined from the EHR, a common practice in health services research. We study the cohort of 4,067 residents of Vancouver Island with severe alcohol addiction. Engagement with the cross-continuum terrain of services is aggraged over 10 years (2007 - 2017) and reported via categories of the Clinical Context Coding Scheme of the Vancouver Island Health Authority.\nRead the full report\nPlay with the pivot of results\nFigure 1: Aggregate cohort engagement of service classes: acute (red) and community (grey)\n\r","date":1564704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564704000,"objectID":"5a9eed4157a906826d635e4a6b1e3403","permalink":"/post/2019-08-01-what-lies-beyond-acute-care/","publishdate":"2019-08-02T00:00:00Z","relpermalink":"/post/2019-08-01-what-lies-beyond-acute-care/","section":"post","summary":"Using service utilization data of 4,067 residents of Vancouver Island with sever alcohol addiction we demonstrate the cross-continuum terrain of health services in Vancouver Island Health Authority.","tags":["electronic health records","heavy addiction","alcohol","substance abuse","health service utilization"],"title":"What Lies Beyond Acute Care Data","type":"post"},{"authors":[],"categories":[],"content":"\rI am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr. Andrea Piccinin and Dr. Scott Hofer. With IALSA, I worked on developing reproducible analytics (R + GitHub) for remote collaboration, particularly for implementing coordinated statistical analyses among multiple longitudinal studies of aging via remote participation.\nInterest in data-driven narratives of human aging lead me to explore the use of electronic health records (EHR) for research and improvement of patient care. Since October 2015 I have been working with Dr. Kenneth Moselle, the director of the Applied Clinical Research Unit (ACRU) of Vancouver Island Health Authority (VIHA) on curating the transformation of VIHA’s EHR into analyzable form and creating opportunities for academic and clinical researchers to work with these data in responsible and reproducible way. Together with Dr. Moselle I have launched a Data Science Studio at the University of Victoria, a research unit at the Institute on Aging and Lifelong Health dedicated to supporting its research affiliates and UVic students in accessing, handling, and modeling cross-continuum health records of VIHA.\nAt ACRU I worked on bridging healthcare data to analytic capacities of longitudinal modelling. My functions at ACRU included statistical and programming support for research and quality improvement projects, coordinating communication and empowering collaboration among three audiences: database managers, medical practitioners, and academic researchers. The overlap in my skills in statistical modeling, programming, and knowledge of VIHA’s electronic health records gave me a unique advantage to facilitate such a collaboration, the integrative nature of which offered great promises for improving patient care, medical science, and methodological practices of longitudinal research.\nIn August of 2017 I was awarded a CIHR Health System Impact Fellowship with BC Observatory for Population and Public Health of the BC Centre for Disease Control ($140,000 + $15,000 development fund). My program of work involved developing a system for population health surveillance that would focus on chronic diseases, with particular focus on mental health and substance use (MHSU) conditions, which tend to have high comorbidity rates, polysubstance use patterns, and slowly progressing pace of development. Drawing on my experience with EHR system employed by VIHA, I engaged various statistical modeling and learning techniques to construct analytic workflows capable of supporting clinical decisions at the point of service, while translating the acquired knowledge to be consumed by clinical stewards, system planners, and surveillance agencies.\nmindset\rData scientists describe the ultimate reality about data using various dialets of expression. Each translation has its benefits and disadvantages. We need them all to tell a good story.\nNo one language is better than the other. Each allows for different shades of distinction in model specification.\n\r","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561058495,"objectID":"b29fbe32d2b65a7f442839fc78fb3f21","permalink":"/post/academic-biography/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/academic-biography/","section":"post","summary":"I am a data scientist with background in quantitative methods and interest in data-driven models of human aging.\nI received my Ph.D. in Quantitative Methods in 2014 from Vanderbilt University, where I studied under Dr. Joe Rodgers, specializing in statistical modeling, design of graphical displays of information, and reproducible research. In August of the same year I joined the Integrative Analysis of Longitudinal Studies of Aging (IALSA) network (NIH/NIA P01AG043362) at the University of Victoria (UVic), directed by Dr.","tags":[],"title":"Academic Biography","type":"post"},{"authors":["Andriy Koval","Anthony Leamon","Kate Smolina"],"categories":["suppress-for-release"],"content":"\rPoster presented at the 2019 conference of the Canadian Association for Health Services and Policy Research, Halifax, Nova Scotia.\nNote: The number in parentheses (1) refers to the section of the poster.\nTake away points\r\rReproducible pipelines are hard, but they pay off\rThink of cognitive load first, computational load second\rInvest into dependency maps for (re-)learning forms \u0026amp; functions\rInvest into workflow maps for (re-)learning structures \u0026amp; processes\r\r\rBackground\rIn 2016, the Observatory for Population \u0026amp; Public Health of British Columbia launched the Chronic Disease Dashboard, an online reporting tool designed to address the gap in surveillance of chronic diseases. To protect against re-identification risks, the Ministry of Health required redacting small counts prior to releasing disease rates into public domain. These preparations, when conducted manually, have proven to be arduous, time consuming, and prone to human error.\n\rApproach\rWhile finding a “small” count (operationalized as “ \u0026lt; 5 ”) was straightforward, detecting conditions, in which suppressed values could be recalculated from related cells involved human judgement. As part of the embedded research by their Health System Impact Fellow (2017), the Observatory set out to automate this task, designing a reproducible workflow ( see section 5 of the poster ) that split data into disease-by-year data frames of a specific form ( 1 ), applied a sequence of logical tests ( 2 ) written to recognize conditions that made recalculation of suppressed values possible and printed a graph ( 6 ) for each case of suggested automatic redaction to be confirmed by a human ( 7 ).\n\rResults\rThe automated suppression was successfully integrated into the Dashboard maintenance. Data preparation, application of logical tests, and production of visual evidence were implemented in R and published as a version-controlled RStudio project on Github github.com/ihacru/suppress-for-release. A fully reproducible example with fictional data was made available to demonstrate the current logic of suppression and to ensure the availability of documentation for the future staff of the Observatory charged with Dashboard maintenance. To assist with learning, we designed a map of dependencies among the custom functions used for suppression ( 4 ) and illustrated their use in a simplified workflow ( 3 ), which allows studying the performance of logical tests before engaging the real data to applying the suppression logic ( 5 ) and to document the redaction decisions ( 7 ) Anticipating the evolution of suppression logic, we moduralized the logical tests ( 2 ) responsible for redaction and provided several options to vary the degree of preserved information ( blue vs light blue ).\n\rConclusions\rThis case of embedded research demonstrates the benefits and feasibility of integrating practices of reproducible analytics into routine workflow of epidemiological surveillance. We make a strong case for employing such learning devices as workflow maps ( 5 ) and function dependency trees ( 4 ) for structuring applied projects and ensuring their reproducibility.\n\r","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"68cee25142656a0448bc697f37c52ad4","permalink":"/publication/koval-2019-suppress-for-release/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/publication/koval-2019-suppress-for-release/","section":"publication","summary":"Demonstrates the methods of suppressing small counts in a provincial surveillance system in preparation of data for public release.","tags":["small cell suppression","chronic disease surveillance","public health","reproducible research","ggplot2"],"title":"Suppressing Small Counts for Public Release","type":"publication"},{"authors":["Emily C Duggan","Andrea M Piccinin","Sean Clouston","Andriy Koval","Annie Robitalle","Andrea R Zammit","Chenkai Wu","Cassandra L Brown","Lewina O Lee","Deborah Finkel","William H. Beasley","Jeffrey Kaye","Graciela Muniz Terrera","Mindy Katz","Richard B Lipton","Dorly Deeg","David A Bennett","Marcus Praetorius Björk","Boo Johansson","Avron Spiro II","Jennifer Weuve","Scott M Hofer"],"categories":["coordinated analysis","IALSA-Portland"],"content":"\rBackground\rSubstantial research is dedicated to understanding the aging-related dynamics among individual differences in level, change, and variation across physical and cognitive abilities. Evaluating replicability and synthesizing these findings has been limited by differences in measurements and samples, and by study design and statistical analyses confounding between-person differences with within-person changes. In this article, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.\n\rMethods\rWe performed coordinated analysis of bivariate growth models in data from 20,586 participants across eight longitudinal studies to examine individual differences in baseline level, rate of change, and occasion-specific variability in pulmonary and cognitive functioning. Results were summarized using meta-analysis.\n\rResults\rWe found consistent but weak baseline and longitudinal associations in levels of pulmonary and cognitive functioning, but no associations in occasion-specific variability.\n\rConclusions\rResults provide limited evidence for a consistent link between simultaneous changes in pulmonary and cognitive function in a normal aging population. Further research is required to understand patterns of onset of decline and differences in rates of change within and across physical and cognitive functioning domains, both within-individuals and across countries and birth cohorts. Coordinated analysis provides an efficient and rigorous approach for replicating and comparing results across independent longitudinal studies.\nSee more\n\r","date":1551484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551484800,"objectID":"50d7843ace7e770a5eb69bfc5db9ddb4","permalink":"/publication/duggan-2018-pulmonary-cognition-aging/","publishdate":"2019-03-02T00:00:00Z","relpermalink":"/publication/duggan-2018-pulmonary-cognition-aging/","section":"publication","summary":"In this second paper of a two-paper series, we conducted a coordinated analysis and summary meta-analysis of new results on the aging-related dynamics linking pulmonary function and cognitive performance.","tags":["pulmonary","cognition","cognitive aging","normative aging","longitudinal analysis"],"title":"A Multi-Study Coordinated Meta-Analysis of Pulmonary Function and Cognition in Aging","type":"publication"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rVisualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?\nThis presentation will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon. The system evaluates synthetic socioeconomic and mortality data with logistic regression. The data was prepared for the hackathon by Statistic Canada and represents Canadian population.\nTopics covered will include:\n\rIntroduction to a visualisation technique that uses color to create meaningful expectations from the results of a logistic regression.\rDetails related to the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon )\rBuilding the case for preference of reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\r\rVideo\r\r\r","date":1541113200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"010a0c32feb7228a67d237e138834c59","permalink":"/talk/2018-11-01-visualizing-logistic-regression/","publishdate":"2018-11-01T16:00:00-07:00","relpermalink":"/talk/2018-11-01-visualizing-logistic-regression/","section":"talk","summary":"Visualising results of statistical modeling is a key component of data science workflow. Statistical graphs are often the best means to explain and promote research findings. However, in order to find that one graph that tells the story worth sharing, we sometimes have to try out and sift through many data visualizations. How should we approach such a task? What can we do to make it easier from both production and evaluation perspectives?","tags":["logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"Visualizing Logistic Regression","type":"talk"},{"authors":["Andriy Koval"],"categories":["functional graphing","reproducible research","statistical learning"],"content":"\rAbstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software. First, I will demonstrate a reproducible graphing system designed for the IPDLN-2018 hackathon, organized by Statistics Canada. The system evaluates synthetic socioeconomic and mortality data with logistic regression. Then I will discuss the workflow of the project that implements this graphing system (github.com/andkov/ipdln-2018-hackathon ) and the RStudio + GitHub setup that hosts it. I will conclude by building the case to prefer reproducible workflows with version control over computational notebooks (e.g. Jupyter, R Notebook).\n\rTable of Content\rFigure 1\n\r\rLayers of Isolation\rFigure 2\n\r\r","date":1541023200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564093645,"objectID":"9ad4009290131c1caf1cde78229fbc07","permalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","publishdate":"2018-10-31T15:00:00-07:00","relpermalink":"/talk/2018-10-31-when-notebooks-are-not-enough/","section":"talk","summary":"Abstract\rWhile computational notebooks offer scientists and engineers many helpful features, the limitations of this medium make it but a starting point in creating software - the practical goal of data science. Where do we go from computational notebooks if our projects require multiple interconnected scripts and dynamic documents? How do we ensure reproducibility amidst growing complexity of analyses and operations?\nI will use a concrete analytical example to demonstrate how constructing workflows for reproducible analyses can serve as the next step from computational notebooks towards creating an analytical software.","tags":["literate programming","computational essays","logistic regression","ggplot2","coloring book","graphing techniques","hackathon","IDPLN"],"title":"When notebooks are not enough","type":"talk"},{"authors":["Andriy Koval","Ken Moselle"],"categories":["Health Informatics"],"content":"\rPoster presented at the 2018 conference of the International Population Data Linkage Association, Banff, Alberta.\n","date":1537660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537660800,"objectID":"ade67b61c6a9760a8540d24f99cd88fb","permalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","publishdate":"2018-09-23T00:00:00Z","relpermalink":"/publication/idpln-2018-banff-clinical-context-coding-scheme/","section":"publication","summary":"Demonstrates how cross-continuum terrain of health services can be described in with flexible classification scheme.","tags":["cccs"],"title":"Clinical Context Coding Scheme","type":"publication"},{"authors":["Amanda Kelly","Matthew Calamia","Andriy Koval","Graciela Muniz-Terrera","Andrea M.Piccinin","Sean Clouston","Linda B.Hassing","David A. Bennett","Boo Johansson","Scott M.Hofer"],"categories":["coordinated analysis"],"content":"\r","date":1456358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456358400,"objectID":"3445af2e990ad454352aed5822303af0","permalink":"/publication/kelly-2016-hypertension-diabetes-memory/","publishdate":"2016-02-25T00:00:00Z","relpermalink":"/publication/kelly-2016-hypertension-diabetes-memory/","section":"publication","summary":"The study explored the effects of living with Hypertension and Diabetes Mellitus on declarative memory performace using data from longitudinal studies from England, Sweden, and the United States.","tags":["cognition","cognitive aging","diabetes","hypertension","longitudinal analysis"],"title":"Independent and Interactive Impacts of Hypertension and Diabetes Mellitus on Verbal Memory","type":"publication"},{"authors":["Andriy Koval"],"categories":["reproducible research"],"content":"\rThe lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.\nOf specific importance is the data grooming stage, which enables a productive exploration of the data and establishes custody chains to support research conclusions based on the analytic products.\n","date":1412899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412899200,"objectID":"d2d2d10b1433ca923ab615ade69d4d28","permalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","publishdate":"2014-10-10T00:00:00Z","relpermalink":"/talk/2014-10-10-toolbox-toolset-reproducible-research/","section":"talk","summary":"The lecture introduces reproducible research and demonstrates digital self-publishing with RStudio and Git (Hub). The skills described and emphasized in this workflow include data manipulation, graph production, statistical modeling, and dynamic reporting. A series of four talks discusses each skill and gives examples of possible implementations in R.","tags":["data science","analytic workflow","dynamic documentation","computational essays"],"title":"Toolbox and Toolsets of Reproducible Research","type":"talk"}]